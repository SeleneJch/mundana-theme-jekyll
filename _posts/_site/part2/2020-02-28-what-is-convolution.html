<p>Issues <br /></p>

<p>1) Kaiming Initializtion in Pytorch was in trouble.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> <br /></p>

<p>2) Jeremy started to dig in, in lesson09, but I didn’t know why the size of tensor is <sup id="fnref:5x5x5"><a href="#fn:5x5x5" class="footnote">2</a></sup> and even understand this spreadsheet data.<sup id="fnref:conv"><a href="#fn:conv" class="footnote">3</a></sup> <br /></p>

<hr />

<h4 class="no_toc" id="homework">Homework</h4>

<p>Read <a href="https://arxiv.org/pdf/1311.2901.pdf">Visualizing and Understanding Convolutional Networks
</a> paper</p>

<hr />

<ul id="markdown-toc">
  <li><a href="#what-is-a-convolution" id="markdown-toc-what-is-a-convolution">What is a convolution?</a>    <ul>
      <li><a href="#visualization" id="markdown-toc-visualization">Visualization</a>        <ul>
          <li><a href="#one-kernel" id="markdown-toc-one-kernel">one kernel</a></li>
          <li><a href="#matthew-d-zeiler--rob-fergus-paper" id="markdown-toc-matthew-d-zeiler--rob-fergus-paper">Matthew D Zeiler &amp; Rob Fergus Paper</a></li>
        </ul>
      </li>
      <li><a href="#convolution-can-be-represented-as-matmul" id="markdown-toc-convolution-can-be-represented-as-matmul">Convolution can be represented as matmul</a></li>
      <li><a href="#padding" id="markdown-toc-padding">Padding</a></li>
      <li><a href="#kernel-has-rank-3" id="markdown-toc-kernel-has-rank-3">Kernel has rank 3</a></li>
      <li><a href="#how-can-we-find-a-side-edge-a-gradient-and-area-of-constant-weight" id="markdown-toc-how-can-we-find-a-side-edge-a-gradient-and-area-of-constant-weight">How can we find a side-edge, a gradient and area of constant weight?</a></li>
    </ul>
  </li>
</ul>

<h3 id="what-is-a-convolution">What is a convolution?</h3>

<p>A convolutional neural network is that your red, green, and blue pixels go into the simple computation, and something comes out of that, and then the result of that goes into a second layer, and the result of that goes into the third layer and so forth.</p>

<h4 id="visualization">Visualization</h4>

<h5 id="one-kernel">one kernel</h5>

<ul>
  <li>Refer this <a href="http://setosa.io/ev/image-kernels/">site</a> for visualizing CNN filtering</li>
</ul>

<h5 id="matthew-d-zeiler--rob-fergus-paper">Matthew D Zeiler &amp; Rob Fergus Paper</h5>

<p><a href="https://youtu.be/BWWm4AzsdLk?t=4588">Lecture01</a></p>

<div style="text-align:center">
    <img src="/assets/images/cnn-nine.png" />
    <figcaption>Nine examples of the actual coefficients from the **first layer**</figcaption>    
</div>

<h4 id="convolution-can-be-represented-as-matmul">Convolution can be represented as matmul</h4>

<p><a href="https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c">CNNs from different viewpoints</a></p>

<p><img src="/assets/images/cnn-result.png" alt="" />{align-items: center;}</p>

<p><img src="/assets/images/cnn-result2.jpg" alt="" /></p>

<ul>
  <li>
    <p>[A B C D E F G H I J] is 3 by 3 image data flatten to vector.</p>
  </li>
  <li>As a result, convolution is a just matrix just two things happens
    <ul>
      <li>Some of entries are set to zeros at all the times</li>
      <li>same color always have the same weight. That called <strong>weight time / wegith sharing</strong></li>
    </ul>
  </li>
  <li>So, we can implement a convolution with matrix multiplication. But, we don’t do that because it’s slow!</li>
</ul>

<h4 id="padding">Padding</h4>

<ul>
  <li>What most of libraries do is just put zeros asdie of matrix</li>
</ul>

<p><img src="/assets/images/padding2.png" alt="" /></p>

<p><img src="/assets/images/padding.png" alt="" /></p>

<ul>
  <li>fast.ai uses reflection paddings (what is this? Jeremy said he uttered it)</li>
</ul>

<h4 id="kernel-has-rank-3">Kernel has rank 3</h4>

<ul>
  <li>As standard picture input would be <sup id="fnref:RGB"><a href="#fn:RGB" class="footnote">4</a></sup> <sup id="fnref:2"><a href="#fn:2" class="footnote">5</a></sup>, it would be actually 3d, not 2d.</li>
  <li>If we make kernel as a 3x3 size, we pass over same kernel all the different Red, Green, Blue Pixels.
    <ul>
      <li>This could make problem, because, if we want to detect frog, which is green, we would want more activations on the green(I made a test cell in my colab <sup id="fnref:3"><a href="#fn:3" class="footnote">6</a></sup>)</li>
    </ul>
  </li>
</ul>

<h4 id="how-can-we-find-a-side-edge-a-gradient-and-area-of-constant-weight">How can we find a side-edge, a gradient and area of constant weight?</h4>

<p>Not top-edge!</p>

<ul>
  <li>One kernel can find only the top-edge, so we should stack the kernels <sup id="fnref:5"><a href="#fn:5" class="footnote">7</a></sup></li>
  <li>So, we pass it through bunch of kernels to the input images, and that process gives us height x width x corresponding number of kernels.</li>
</ul>

<p><img src="/aassets/images/tensors.png" alt="" /></p>

<ul>
  <li>Usually that number of chanel is 16</li>
  <li>And if we want to get the more channels and features, we should repeat that process
    <ul>
      <li>This process gives rise to memory out of control, we do the <strong>stride</strong></li>
    </ul>
  </li>
</ul>

<p>####</p>

<p><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA">conv-example.xlsx</a></p>

<ul>
  <li>2 convolutional filters</li>
  <li>At a second layer, filter is 3x3x2 tensor, because to add up together the first layer’s channel.</li>
</ul>

<!-- Actually, what I wanted to know part :  -->

<hr />

<h3 class="no_toc" id="reference">Reference</h3>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Problem was <em>math.sqrt(5)</em> was not kaiming initialization formula, <a href="https://github.com/pytorch/pytorch/blob/3df79f403e8b9621d5adb0447266becd10d633b0/torch/nn/modules/linear.py#L58-L63">Implementation in Pytorch</a> <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:5x5x5">
      <p><a href="https://youtu.be/AcA8HAYh7IE?list=PLBRuZVGXwM3l2HesxBCrvwYacG1AWrVmM&amp;t=251">size of tensor, lecture09</a> <a href="#fnref:5x5x5" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:conv">
      <p><a href="https://github.com/fastai/course-v3/blob/bc034b471d839bdf5bc72bd7fec1061fac648ccd/files/xl/conv-example.xlsx">conv-example.xlsx</a> <a href="#fnref:conv" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:RGB">
      <p><a href="https://www.quora.com/Why-do-computers-use-red-green-and-blue-instead-of-the-primary-colors">Why do computer use red, green and blue instead of primary colors</a> <a href="#fnref:RGB" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Grayscale is a group of shades without any visible color. … Each of these dots has its own brightness level as well and, therefore, can be converted to grayscale. A grayscale image is one with all color information removed. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://brohrer.github.io/convert_rgb_to_grayscale.html">Testing RGB and grayscale</a> <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p><a href="https://youtu.be/hkBa9pU-H48?t=4937">stack kernel and make new rank of tensor at output, Lesson06-2019</a> <a href="#fnref:5" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
