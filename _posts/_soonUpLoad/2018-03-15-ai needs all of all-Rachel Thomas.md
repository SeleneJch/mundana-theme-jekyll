---

layout: post
title: ThomasxTed, AI needs all
modified: 2019-10-15
categories: [AI&Ethics]
tags: 
comments: true

---



---

following is substription of her video.

[Music] so who's excited about AI yeah oh yeah who's nervous about it okay I see a mix I feel both and there's good reason AI is a complex and controversial topic and we're hearing all sorts of conflicting messages killer robots are gonna take all our jobs and murder us and I will cure cancer and I sure in Utopia this is just marketing height then AI is nothing but a buzzword there is a kernel of truth in all these statements but the reality is more complex and nuanced it's natural to feel like if you're not a math genius or you don't have a PhD from Stanford that you couldn't possibly hope to understand what's going on much less to get involved I'm here to tell you that is false it is not only possible for everyone to get involved with AI it is actually crucial that you do so I say this is someone who is an unlikely person to become an AI researcher and we need more unlikely people in the field both to address the harms that are being caused as well as to take full advantage of the positive opportunities but first what is ai ai refers to any technique that allows a computer to appear to be acting with some level of intelligence ai is in products like how Google photos automatically organizes your picture collection here it's grouped together temples skyline and food into separate categories ai is in Skype translator which lets people speaking different languages communicate in real-time these are both examples of a particular type of AI called deep learning in the past couple of years deep learning has achieved better than human results on tasks that we used to think only humans could do like recognizing pictures and understanding speech one misconception about AI researchers is that we're all trying to recreate a human brain or to get a computer to achieve human consciousness many of us are not many of us including me are interested in practical solutions to real-world problems like identifying lung cancer on a CT scan I'll talk more about some of these positive applications in a moment but first I wanna address three aspects of AI that worry me the first is that AI is encoding and magnifying human bias computer vision has repeatedly performed worse on people of color research earlier this year from joy ballon weeny and Tim Nick gabru evaluated computer vision products from IBM Microsoft and elsewhere and they found that these products performed worse on women than on men and were some people with dark skin compared to people with light skin for instance IBM's computer vision software was 99.7% accurate on light skinned men and only 65% accurate on dark skinned women that's ridiculous that's a huge difference 34% bias is also being encoded in language and translation tools like Google Translate if you give Google Translate pair of English sentences she is a doctor he is a nurse translate those into Turkish which has a gender-neutral singular pronoun and then back into English they come back with the genders flip to fit the stereotype he is a doctor she is a nurse and this is just one example out of many biases that are encoded in Google Translate second area that worries me is that AI is promoting and incentivizing conspiracy theories people watch over 1 billion hours of YouTube per day that's per day that's a--that's huge and part of YouTube's success is because of its recommendation algorithm so when you're watching YouTube there's a side bar that says up next and has several videos selected by an algorithm these recommendations disproportionately include conspiracy theorists and white supremacists this phenomena has been investigated by The Wall Street Journal and The Guardian and it's been written about in the New York oh sorry it's been written about and then you are time's so what's going on here this is not an intentional evil plot but YouTube's algorithm is trying to maximize how much time people spend watching YouTube because they earn more money that way and conspiracy theorists watch way more YouTube than people that trust a variety of media sources time we spend on other media sources is bad for YouTube's bottom line so Google which which owns YouTube is earning a lot of money while pumping pollution into the rest of society in this case that pollutions in the form of the political and social impact of having lots of people who believe conspiracy theories and distrust mainstream media sources in addition to even egging on conspiracy theorists to come out with more extreme material because that's what that's what's rewarded the problems posed by AI can often feel very new but in this case this problem of what to do when a company's profiting while offsetting its cost everyone else not something that economists and public policy experts have been looking at for ages and we could use their help here and before I explain the third area let's start by watching this video so you'll see some green and red rectangles on the left and those are identifying people's heads and faces even though this video is at a distance and there are people are in a crowd I find this pretty creepy AI can be used by authoritarian governments for surveillance so currently in China million people who are members of an ethnic minority are in internment camps and surveillance has helped facilitate that this said this video is from a Chinese company called deep glint it's two years old the technology's only continue to advance since then last year there was research on how to identify protesters in a crowd even if they're wearing hats or scarves to try to conceal their identities and this is not just a problem abroad in the United States earlier this year we learned that Palantir which is a tech company founded by billionaire and Trump donor Peter Palantir had been using New Orleans as a testbed for its predictive policing technology for the last six years this program was so secretive that even City Council members didn't know about it much less have any oversight Amazon is already selling facial recognition software to police and the software is in use by police in Orlando and Oregon even though the ACLU is raising concerns about the racial bias and inaccuracy of Amazon software I think the combination of a total lack of accountability transparency or oversight together with racial bias and existing police data that will be used to train these algorithms together with the repeated failure of computer vision on people of color makes this a really frightening combination so part of the reason that we're seeing so many unsettling and even scary applications of AI is because of how incredibly narrow the group of people that's creating it is and how many of us are not represented by that group only 12% of machine learning researchers are women the numbers are similarly dire when it comes to race geo diversity and background on top of this people in tack are often building AI without any sort of input or collaboration from fields like sociology psychology or history that can help us better understand how Tech and humans interact I've personally experienced how toxic the environment can be in academic STEM fields and in the tech industry and it scares me that the same people responsible for creating these toxic environments are the primary ones creating powerful AI technology I am an AI researcher but I'm a very unlikely person to have become an AI researcher and my goal is to help more unlikely people find their way into the field I felt like an outsider my entire life I could never find the community I was looking for not in academia and not in tact so I eventually decided to create that community for myself for other outside for people who have been excluded or who can't afford the resources I grew up on the Gulf Coast of Texas near a cluster of chemical refineries I attended a poor predominantly black public high school that was later ranked in the bottom two percent of Texas schools I was pepper sprayed by police while I was at school and there are some great students and teachers at my school but even as a teenager was clear we did not have the resources or the opportunities that wealthier schools had and we were not treated the same unlikely as it was I completed my PhD in math I did not fit in like most math PhD programs my program was almost entirely male I experienced sexism harassment and isolation I watched several of my female friends drop out due to the culture my thesis advisor even told me I was too feminine to be successful and he later stopped meeting with me it was it was devastating years later I sold my car my furniture and most of what I owned to move to San Francisco with just two suitcases and a new dream of becoming a data scientist I did not know anybody who worked in tech it was not a career option I'd really been exposed to and I feel like people in tech were speaking a foreign language eventually I achieved my goal and I landed a job as a data scientist and software engineer at an up-and-coming startup that would later go on to become a multi-billion dollar company and a household name everyone kept telling me I'd made it but I was miserable once again I did not fit in the environment was aggressive sexist isolating and I dreaded going to work each morning during the same period of time I first got interested in deep learning in 2012 I read a New York Times article about an academic group that had no expert knowledge of biochemistry but was using deep learning to automatically design new pharmaceutical drugs is exactly the type of practical AI I'm interested in as I told friends and acquaintances what I was learning many people told me that they could never understand AI that they weren't smart enough or their brain wasn't wired the right way these are all myths this is completely false for a number of reasons as I got deeper into the field and learned the practical techniques needed to create state-of-the-art models I saw that in most cases the math theory wasn't even necessary to become a working practitioner I also saw that the field was unnecessarily exclusive in 2013 I went to a talk that a star in the field was giving and I asked him a simple practical question during the Q&A; he not only didn't answer my question he told me that nobody who knew the answer so people like him nobody was writing it down if you weren't part of the inside crowd tough luck but it doesn't have to be like that for much of my life I thought it was a negative that I didn't and couldn't fit in I sometimes even wish there could be a different person so I could better fit into the toxic environments I was in but it turns out that weasely don't fit in or valuable they allowed me to see a gap that the current system and academia and in tag and in the AI community isn't built for people like me it's not built for most of us my different background allowed me to create something different two years ago I partnered with Jeremy Howard who's a philosophy major with no graduate degree and no formal machine learning training and we decided to create a course to teach state of the art deep learning with no advanced math prerequisites and we made this available completely for free our motto is making neural networks uncool because being cool is about being exclusive and that's the opposite of what I want we've had 10 so most people who take our course are working professionals doing this in their spare time and we've had tens of thousands of people take the class and apply deep learning to problems they care about whether this is at nonprofits or our fortune 500 companies launching startups or winning half as I'm a despite all these success stories I continue to hear from experts saying that what we're doing is impossible we're disproving the myth that you need the fanciest most expensive computer and the fanciest most prestigious background to do cutting-edge work earlier this year a group of our part-time students entered a competition against engineers from Google and Stanford artists like Google and Intel and these teams at Google and Intel had access to way more expensive computers yet our team won theirs thank you yeah I'm so proud of them for this this was covered in the verge and the MIT tech review and they're showing that you don't have to work at Google or have Google like resources to do state-of-the-art work one person who's taken our courses Melissa Fabrice Melissa was an English literature PhD student focused on American poetry before switching careers a few years ago she's now an engineer at the microlending nonprofit Kiva which lets people make small loans to entrepreneurs around the world Melissa discovered that computer vision software couldn't identify pictures of Kiva users because the software was primarily trained by a non-white people Melissa won a prestigious grant to help fund her project to address this another person who's taken our class is Sarah hooker Sarah was an economics major who only learned to code a few years before the class Sarah started Delta analytics to pair data scientists with nonprofits Sarah and a team worked with rainforests connection which puts recycled cell phones up on trees and endangered rainforest streams audio and then uses deep learning to identify chainsaw noises if someone's illegally cutting down the forest they're experts who say our students will never get jobs in the field yet Sarah now works for Google and is helping to open Google's first AI Research Center in Africa these are just a few stories out of many other people who have taken our class have helped farmers in India created wearable devices for patients with Parkinsons disease invented new styles of artwork and music and even had their work featured on HBO and in Forbes I was contacted by a Canadian Canadian dairy farmer who wants to use deep learning to improve the health of his goats utters I never would have guessed that AI could be applied to go daughters but this is exactly the type of person I want to help I want to help other unlikely people other outsiders people sometimes ask me if it's dangerous to make AI accessible to more people what's dangerous is having an exclusive and homogeneous group creating technology that impacts us all we've seen the harms being caused by companies like Facebook Google YouTube Amazon Palantir and others and we need people from more diverse backgrounds to try to address those harms we need people from communities that have been disproportionately targeted with harassment to help create our technology because they have a deeper understanding of how tech can be weaponized against the most vulnerable and of what safeguards we need to put in place and we also need more people who are experts about people about human behavior human psychology and human history the reason I want everyone involved with AI is that you know about problems nobody else knows about and you have skills in a background that nobody else has I didn't know about using old cell phones to protect the rainforest about the suicide rate for farmers in India or about the health of NGO daughters yet these are all problems my students have worked on I'm so glad that my students didn't believe the myth that AI is only for math prodigies but that they knew their perspectives are valuable we need journalists Boyer's hospital administrators hotel sales managers sociology CEOs historians and more to understand the capabilities of AI it doesn't matter if you didn't go to the right school if math makes you anxious if your friends and colleagues think you're the last person that ever expects be working with AI AI needs more unlikely people and the world needs you involved with AI thank you [Applause]