---
layout: post
title: "fastai 2020 course-v4 Part1, lesson06"
author: dionne
categories: [ fastai-v4 ]
image: assets/images/lesson6-v4.png
---

Jeremy:note lesson6 for: [Deep Learning Part 1 of Spring 2020 at USF](https://www.usfca.edu/data-institute/certificates/deep-learning-part-one)

Today we will study
1. Image Classification
2. Multi-label classification
3. Collaborative filtering

## CONTENTS
{: .no_toc}

- [Image Classification](#image-classification)
{:toc}

Previous; Recap of last class

## Image Classification

### Model Interpretation

[course link](https://render.githubusercontent.com/view/ipynb?commit=56ab576a6826ecea66ed555b3b46a90ed409bb19&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f636f757273652d76342f353661623537366136383236656365613636656435353562336234366139306564343039626231392f6e62732f30355f7065745f6272656564732e6970796e62&nwo=fastai%2Fcourse-v4&path=nbs%2F05_pet_breeds.ipynb&repository_id=248051827&repository_type=Repository#Model-Interpretation), [Book link](https://render.githubusercontent.com/view/ipynb?commit=56ab576a6826ecea66ed555b3b46a90ed409bb19&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f636f757273652d76342f353661623537366136383236656365613636656435353562336234366139306564343039626231392f6e62732f30355f7065745f6272656564732e6970796e62&nwo=fastai%2Fcourse-v4&path=nbs%2F05_pet_breeds.ipynb&repository_id=248051827&repository_type=Repository#Model-Interpretation)

- When you have many categories, use `most_confused()` method rather than plotting confusion matrix (#q) no way to see with regression model?

### Improving our model

#### Learning rate finder

- `learn.fine_tune()` has `base_lr`parameter (changed from `fit_one_cyle` of fastai\_v1)
- If learning rate is too high, loss validation gets too high compared to loss of train
	-  why? because it diverges
- If learning rate is too small, train loss decreases too slowly, and there are much gap between train and valid loss.
	- (#q) But how do I know if loss decreases slowly or not?
	- So it will take long time, means too many epochs, resulting overfitting 
- meaning of `learning rate graph`: `loss` graph
	- (#q) Is it train loss or valid loss what plot shows

> `lr\_find()` goes through (#f)one batch?
Jeremy: no, each lr candidate goes through one minibatch for each lr, 
> why steepest? why not minimum?
Jeremy: we want our model to enhance learning while training
	- (#q) Is this related to fit_one_cycle learning?

#### Unfreezing and transfer learning

(#f)

~~~
learn.find_tune??
~~~

(#q) what's diff from fit\_one\_cycle?

- calling `cnn_learner` freeze our model, so don't have to do it seperately
- We can do better because we just used the same learning rate for a whole training

####  Discriminative learning rates

![](/assets/images/discriminative_lr.png)

- use `slice` at lr_max parameter means discriminative learning rate
	- why *lr_max*? first layer use use left value of slice, and last layer use right value of slice (#q)(I need to study more of scheduled learning)

#### Selecting the number of epochs

- If you choose too big epoch, valid\_loss will not change from specific point, and this is related to `fit_one_cycle`

- What `fit_one_cycle` does?
	- (#f) `???? -  couldn't get why`
	- if error_rate stop from specific epoch, use that epoch as epoch and do it again


#### Deeper architectures

- Generally people don't use resnet18, resnet34
- about, `.to_fp16()`: NVIDIJeremy:GPU support special tensor and it's faster about 2x/3x (#q) import what module?: from fastai2.callback.fp16 import *
- Try a small model before scaling up the model < because bigger model doesn't guarantee better performance

### Jeremy:signment

- Read paper, [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186) and see how you can get best results with adjusting learning rate, find out best learning rate by yourself!

--- 

>  about `.to_fp16()` (#f)
Jeremy: (#f)
>  (#f)
Jeremy: not does machine learning but  deep learning specifically. For more info, see Rachael's Linear Jeremy:gebra course.

## Multi-label classification

### Constructing a data block

- dataset is abstract idea of class
	- If you index it mostly get tuple, independent variable and dependent variable.(#todo) diff between `(a,)` and `(a)`
	- when you use (#f) `a` is independent(input), and `0` is dependent variable(target)
- Dataloader is (#f)
(#f) (#todo) [read the book](https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30365f6d756c74696361742e6970796e62&nwo=fastai%2Ffastbook&path=06_multicat.ipynb&repository_id=243838973&repository_type=Repository#Constructing-a-data-block)
 
- Datablock does male train and valid set for us
- Randomly split so we have different output when we call dataset (#todo) use random.seed to get a same output

~~~
dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
                   get_x = get_x, get_y = get_y)
dsets = dblock.datasets(df)
dsets.train[0]
~~~

`
(PILImage mode=RGB size=500x375,
 TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))`

- `PILImage mode=RGB size=500x375`: independent variable, which is a input
- (#f) make image size same, and call data loaders

> why we don't train with 8 bit data
Jeremy: (#f) couldn't hear, but bumpy...?

> one hot encoding is int, but why output(`TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))`) is float?
Jeremy: because we *will* use cross-entropy style loss. 

> Is it possible that I make a data loaders with character label like 'desk'?
Jeremy: Yes. Use index if it's category and will study next time when it's continuous variable.



#### Binary cross entropy
~~~python
learn = cnn_learner(dls, resnet18)
x,y = dls.train.one_batch()
activs = learn.model(x)
activs.shape
~~~
- when you render the one size of batch to the model, you can get an output.
- Use a`dls.train.one_batch()` function when you check what's going in and out, especially see a shape of tensor.

~~~python
def binary_cross_entropy(inputs, targets):
    inputs = inputs.sigmoid()
    return -torch.where(targets==1, inputs, 1-inputs).log().mean()
~~~

- result is 0 to 1 but we get a variable between 0 and 1 so that we use sigmoid
- (#todo) find out why use .log last chapter`
- (#todo) [read the book](https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30365f6d756c74696361742e6970796e62&nwo=fastai%2Ffastbook&path=06_multicat.ipynb&repository_id=243838973&repository_type=Repository#Binary-cross-entropy)


(#f)


- One-hot encoded target, use `BCELoss`
- accuracy as a metric only works at single label dataset
	- because accuracy uses argmax which chooses single number
- so doing multi-categorical problem, use accuracy which check threshold(not selecting one value), and pass the number over threshold
- `partial` function is used when you want to fix one parameter (#f) (#q) why we have to fix

~~~
learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))
~~~

- How can I get *best* threshold?


~~~python
preds,targs = learn.get_preds()
xs = torch.linspace(0.05,0.95,29)
accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs]
plt.plot(xs,accs);
~~~
- (#f) about overfitting because we selected best number	

### [Regression](https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30365f6d756c74696361742e6970796e62&nwo=fastai%2Ffastbook&path=06_multicat.ipynb&repository_id=243838973&repository_type=Repository#Regression)

#### Jeremy:semble the data

- `get_image_files` gather image recursively
- `splitter` why select exact person? -> it's continuous frame, so if you just select random data, it would be overestimated.
- do the same thing using one_batch, and then see shape of output.
- image as 3 channel, you can see the version of `R`, `G`, `B`
	- you can draw bear using this code (#f) no code at course note


> can we give multi-channel bigger than 3?
Jeremy: yes, it used often like when you use satellite image. But your pre-trained model is usually for a 3-channel and fastai (#f) could not listen



#### Training a mode
~~~python
learn.show_results(ds_idx=1, max_n=3, figsize=(6,8))
~~~

- left of output is target, right is prediction
- *Notice* that we used pre-trained model, which did classification task. But it works well when you do regression with it.
	- why? pre-trained model from ImageNet is collection of image's features like, objects, color, texture, shadow and so on
	- so from pre-trained model, we can get the *features* of an image, and do the *other job*(e.g., regression) with fine-tuning

### Jeremy:signment

- go to the bear classifier, and find out when you give image which is not included in label and see what happens (#q) why?
- This will be helpful when you change from multiple-category ... (#f)

---

> used cross-validation doing machine learning . Do we use it at deep learning?
Jeremy: First, nowadays cross-validations are less common(at least at kaggle), because cross-validation was used there were not lots of data. Second, cross-validation is not related selection between machine learning and deep learning

> CF algorithm used other than recommendation system.(#f)
Jeremy: whatever it's kind of recommendation system.

> how can i make data set if I have video? how split?(time phrase)
Jeremy: rank-5 tensor by (time, h, w, batch, (#f)). you can make this theoretically but it is not practically used because too big tensor leads to out of memory

## [Collaborative filtering](https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30385f636f6c6c61622e6970796e62&nwo=fastai%2Ffastbook&path=08_collab.ipynb&repository_id=243838973&repository_type=Repository#Collaborative-filtering-deep-dive)

- (#todo) Read the fastbook
- CF algorithm is related to *latent*  variable(;factors) since we don't have *a label explaining/depicting properties* which made you choose specific movie
	- In other words, there is no specific label how we could predict the dependent variable(recommendation; movies user didn't watch) results from independent var(rating regarding user and movie)

![](/assets/images/pic1-v4-L6.png)

- upper and below part represent same info
- It does dot product and sum with user and movie weight matrix

### Learning the latent factors

- randomly create user's factor(;latent, hidden) and movie's factor. and do matrix multiplication with those, which is dot product.
- and sum it and compare with target, so that you can learn parameters, which were randomly initialized

### Creating the DataLoaders

-  Let's make DataLoaders using basic python and PyTorch!

- user and movie is represented using index, label,..,called look up in an index
- but *look up in an index* is not the thing that deep learning models know how to do with. (#q) why?: I think because it can't do matrix multiplication
	- so that we make one-hot encoding matrix

> how to do with sparse data?
Jeremy: see course rachael's linear algebra

- embedding layer: multiplying by a one hot encoded matrix, using the computational shortcut that it can be implemented by simply indexing directly.(#todo) watch again this part of v3, Jeremy explained with excel
	- This is important : embedding is not magic, it's just computational shortcut to make kind of one-hot encoding mat mul with look up index


### Collaborative filtering from scratch

- importance of dunder method of python. (like `__init__`)
	- explained OOP concept
- Inheritance of python
- Module is fast.ai version of pytorch's nn.Module
- Remember Embedding is just kind of shortcut to make a one-hot encoding matrix 

~~~python
class DotProduct(Module):
    def __init__(self, n_users, n_movies, n_factors):
        self.user_factors = Embedding(n_users, n_factors)
        self.movie_factors = Embedding(n_movies, n_factors)
        
    def forward(self, x):
        users = self.user_factors(x[:,0])
        movies = self.movie_factors(x[:,1])
        return (users * movies).sum(dim=1)
~~~

- 64: size of mini\_batch, 2: index

~~~
x,y = dls.one_batch()
x.shape
~~~
`torch.Size([64, 2])`

- We use bias to represent specific character of *each user and movie*, because user/movie weight can't show users' character, who usually give good rates, or are fond of animation(movie also)
- what should we do when model is overfitting very quickly with small epoch(#q) how do we know it's quick or not? i.e. it's overfitting or not?
- what should we do to evade overfitting and don't want to lessen epoch?
	-  do regularization, which is panalize the fast learning
- (#q) why just doesn't leave it to learn fast?: I think fast learning doesn't mean model did learn generalized feature. -> then how do we know this is the moment model learned genralized feature? 
- (#q) Isn't there any side effects when you did too much regularization?


> Collaborative filtering algorithm works better than svd or kind of that?
Jeremy: yes

- Use generic `Learner` not cnn\_learner of kind of that. and so that we should render loss function, and model (not using default params)

(#todo) comment about hashtags, check toc