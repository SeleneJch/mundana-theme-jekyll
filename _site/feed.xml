<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-06-13T23:28:43+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">SpellOnYou</title><subtitle>Be afraid only of standing still. Remain fresh, body and soul.</subtitle><entry><title type="html">CS224N: NLP with Deep Learning | Winter2019 | Lecture5</title><link href="http://localhost:4000/2020/06/cs224n-19w-course5/" rel="alternate" type="text/html" title="CS224N: NLP with Deep Learning | Winter2019 | Lecture5" /><published>2020-06-10T00:00:00+09:00</published><updated>2020-06-10T00:00:00+09:00</updated><id>http://localhost:4000/2020/06/cs224n-19w-course5</id><content type="html" xml:base="http://localhost:4000/2020/06/cs224n-19w-course5/">&lt;h1 id=&quot;dependency-parsing&quot;&gt;Dependency Parsing&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Contents of lecture 05&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Syntactic Structure&lt;/li&gt;
  &lt;li&gt;Dependency Grammar and Treebanks&lt;/li&gt;
  &lt;li&gt;Transition-based dependency parsing&lt;/li&gt;
  &lt;li&gt;Neural dependency parsing&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;“We will focus more on how human language is made and used”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;HW3:&lt;/strong&gt; Dependency parsing and neural network foundations &lt;a href=&quot;https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/assignments/a3.zip&quot;&gt;code&lt;/a&gt; &lt;a href=&quot;https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/assignments/a3.pdf&quot;&gt;handout&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;syntactic-structure&quot;&gt;Syntactic structure&lt;/h2&gt;

&lt;p&gt;1) Phrase Structure [Grammar]&lt;br /&gt;
organizes words into &lt;strong&gt;nested constitutes&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Phrase structure examples
    &lt;ul&gt;
      &lt;li&gt;NP -&amp;gt; DET + (ADJ) + N + PP&lt;/li&gt;
      &lt;li&gt;PP -&amp;gt; Prep + NP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Different languages have different phrase structure.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2) Dependency Structure
&lt;br /&gt;: which words &lt;em&gt;depend on&lt;/em&gt;(modify / arguments) which other words&lt;/p&gt;

&lt;h3 id=&quot;why-this-syntactic-structure-is-important&quot;&gt;Why this syntactic structure is important?&lt;/h3&gt;

&lt;p&gt;1) Prepositional phrase attachment &lt;strong&gt;ambiguity&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;San Jose cops kill man with knife&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;with knife&lt;/code&gt; modifies &lt;code class=&quot;highlighter-rouge&quot;&gt;man&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;with knife&lt;/code&gt; modifies &lt;code class=&quot;highlighter-rouge&quot;&gt;San Jose cops kill man&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;The board approved [its acquisition] [by Royal Trustco Ltd] [of Toronto] [for $27 a share] [at its monthly meeting].&lt;/code&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/cs224n/l5-pp.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Catalan_number&quot;&gt;Catalan numbers&lt;/a&gt; &lt;script type=&quot;math/tex&quot;&gt;C_n = \frac{2n!}{(n+1)!n!}&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An Exponentially growing series, which arises in many tree-like contexts:&lt;/li&gt;
  &lt;li&gt;e.g., the number of possible triangulations of a polygon with n+2 sides
    &lt;ul&gt;
      &lt;li&gt;turns up in triangulation of probabilistic graphical models(cs228)…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2) Coordination scope ambiguity&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Doctor: No heart, cognitive issues&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;No [heart and/or cognitive] issues&lt;/li&gt;
  &lt;li&gt;[No heart] and [cognitive issues]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;3) Adjectival Modifier Ambiguity&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Students get first hand job experience&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Students get [[first hand] [job] experience]&lt;/li&gt;
  &lt;li&gt;Students get [[first [hand job] experience]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;4) Verb Phrase (VP) attachment ambiguity&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Mutilated body washes up on Rio beach to be used for Olympics beach volleyball&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Mutilated body washes up on [Rio [beach to be used for Olympics beach volleyball]]&lt;/li&gt;
  &lt;li&gt;Mutilated body [washes up on Rio beach] to be used for Olympics beach volleyball&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;dependency-grammar&quot;&gt;Dependency Grammar&lt;/h2&gt;

&lt;p&gt;Two ways of representing the dependency structure of sentence&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;in a line and drawing arrows&lt;/li&gt;
  &lt;li&gt;tree structure&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Generally, people type arrows with the name of grammatical relationships, but in this case we will not go that far ahead.&lt;/p&gt;

&lt;p&gt;Dependency tree is acyclic, single-head, connected.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dependency Grammar/Parsing history&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;treebanks&quot;&gt;Treebanks&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://universaldependencies.org/&quot;&gt;Universal Dependencies&lt;/a&gt;, cf (#todo fill out)&lt;/p&gt;

&lt;p&gt;People annotated structure dependencies heuristically (And this project handles with many languages other than English)&lt;/p&gt;

&lt;h3 id=&quot;dependency-conditioning-preferences-some-dependency-rules&quot;&gt;Dependency Conditioning Preferences (some dependency rules)&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Only one word is a dependent of ROOT&lt;/li&gt;
  &lt;li&gt;Don’t make it cyclic.&lt;/li&gt;
  &lt;li&gt;in little case, bootstrapping happens(when parse becomes non-projective)
    &lt;ul&gt;
      &lt;li&gt;will comment further at next class&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;arc-standard-transition-based-parser&quot;&gt;Arc-standard transition-based parser&lt;/h2&gt;

&lt;p&gt;Shift &lt;code class=&quot;highlighter-rouge&quot;&gt;Buffer&lt;/code&gt;’s element to left &lt;code class=&quot;highlighter-rouge&quot;&gt;Stack&lt;/code&gt;, until stack finds &lt;code class=&quot;highlighter-rouge&quot;&gt;Head&lt;/code&gt; component.
&lt;br /&gt;-&amp;gt; When you find head at stack, start to reduce
&lt;br /&gt;-&amp;gt; but notice not to reduce &lt;code class=&quot;highlighter-rouge&quot;&gt;head&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; until buffer has no element.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Left Arc means reduction of left argument, and keep head&lt;/li&gt;
  &lt;li&gt;Right Arc means reduction of right argument, and keep head.&lt;/li&gt;
  &lt;li&gt;Finish condition is when buffer is empty, and stack has only one element, which is &lt;code class=&quot;highlighter-rouge&quot;&gt;[root]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But the problem of this method is how we choose the next step is uncertain.&lt;br /&gt;
Usually these problem was handled using Dynamic programming to avoid too much selection cases.&lt;/p&gt;

&lt;h2 id=&quot;neural-dependency-parsing&quot;&gt;Neural dependency parsing&lt;/h2&gt;

&lt;p&gt;1) MaltParser&lt;/p&gt;

&lt;p&gt;[Nivre and Hall 2005]&lt;/p&gt;

&lt;p&gt;built ML classifier,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Accuracy = \frac{\#\ correct\ deps}{\#\ of\ deps}&lt;/script&gt;

&lt;p&gt;UAS = 4 / 5 = 80% (exclude label)
&lt;br /&gt;LAS =  2 / 5 = 40% (include label)&lt;/p&gt;

&lt;p&gt;2) Conventional Feature Representation was very complex.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;incomplete&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;expensive computation&lt;/strong&gt; (critical problem)&lt;/li&gt;
  &lt;li&gt;sparse&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3) Neural dependency parsers&lt;/p&gt;

&lt;p&gt;[Chen and Manning 2014]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sent. / s&lt;/code&gt; means number of sentences that algorithm can perform.&lt;/li&gt;
  &lt;li&gt;Not only fastest methods, but also accuracy gets almost highest.&lt;/li&gt;
  &lt;li&gt;the dense representation is the key&lt;/li&gt;
  &lt;li&gt;Used &lt;strong&gt;treebanks&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4) Further researches&lt;/p&gt;

&lt;p&gt;done by Google&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Using bigger, deeper networks, tuned hyperparameters&lt;/li&gt;
  &lt;li&gt;Beam search&lt;/li&gt;
  &lt;li&gt;Global inference, CRF over the decision sequence&lt;/li&gt;
&lt;/ul&gt;</content><author><name>dionne</name></author><summary type="html">Dependency Parsing</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/cs224n/gate-l5.png" /></entry><entry><title type="html">CS224N: NLP with Deep Learning | Winter2019 | Lecture2</title><link href="http://localhost:4000/2020/06/cs224n-19w-course2/" rel="alternate" type="text/html" title="CS224N: NLP with Deep Learning | Winter2019 | Lecture2" /><published>2020-06-05T00:00:00+09:00</published><updated>2020-06-05T00:00:00+09:00</updated><id>http://localhost:4000/2020/06/cs224n-19w-course2</id><content type="html" xml:base="http://localhost:4000/2020/06/cs224n-19w-course2/">&lt;p&gt;Images: Vector directions related to word classes (&lt;a href=&quot;https://www.semanticscholar.org/paper/An-Improved-Model-of-Semantic-Similarity-Based-on-Rohde-Plaut/73e6351a8fb61afc810a8bb3feaa44c41e5c5d7b&quot;&gt;Rohde et al. 2005&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Course: &lt;a href=&quot;http://onlinehub.stanford.edu/cs224&quot;&gt;Stanford cs224n 2019 winter, lecture 02&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;word-vectors-and-word-senses&quot;&gt;Word Vectors and Word Senses&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Finish last time’s lecture&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(showed more examples)&lt;/p&gt;

&lt;p&gt;and we can see the problem it can’t represent the &lt;strong&gt;polysemy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;drawed PCA: remember this way we lose lots of information because we just chose first two principle components&lt;/p&gt;

&lt;p&gt;&lt;em&gt;purpose of this class is just end of the course you can read paper(from classical to contemporary), and understand them&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;what is parameter of word2vec&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Only two, input vector and output vector&lt;/p&gt;

&lt;p&gt;each vector is represented as ROW (at almost all of modern ML library)&lt;/p&gt;

&lt;p&gt;We are going with just one &lt;strong&gt;probability&lt;/strong&gt; -&amp;gt; same prediction at each point.&lt;/p&gt;

&lt;p&gt;quite interesting cz model is so simple and works well&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Tip: &lt;a href=&quot;https://en.wikipedia.org/wiki/Function_word&quot;&gt;Function word&lt;/a&gt; has fix high probability, (they are closed) so removing it results in better Word Vectors &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Brief explain of optimization&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;actual loss function would be more complex, bumpy, not convex&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Problem of this model and Stochastic Gradient Descent&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;our objective function has to deal with every each element of corpora.&lt;/li&gt;
  &lt;li&gt;Nobody uses this since &lt;a href=&quot;https://en.wikipedia.org/wiki/Computational_complexity_theory&quot;&gt;cost efficiency&lt;/a&gt; is very horrible&lt;/li&gt;
  &lt;li&gt;So we use SGD (not just one data but with group, which is called &lt;code class=&quot;highlighter-rouge&quot;&gt;batch&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Shortage of SGD&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tends to end up sparse distribution, so that usually use (probability) smoothing.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Details of Word2vec&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Why do we learn two vectors ? M: effective, easy to partial derivative. if we use just one parameter, math becomes more difficult, but practically you average it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;skip-grams/CBOWs&lt;/li&gt;
  &lt;li&gt;Naive softmax is slow because it use all the vocabulary.&lt;br /&gt;
Idea: Train &lt;code class=&quot;highlighter-rouge&quot;&gt;Binary Logistic Regression&lt;/code&gt;
    &lt;ol&gt;
      &lt;li&gt;numerator : actually observed, give high prob&lt;/li&gt;
      &lt;li&gt;denominator : noise, which was randomly selected.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;HW2: The skip-gram model with negative sampling&lt;br /&gt;
&lt;strong&gt;k&lt;/strong&gt; would be anything the size of sample you want to choose&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;P(w) = \frac{U(w)^{\frac{3}{4}}}{Z}&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;It comes out that this experiment is not that replicable(which needs lots of hyper-parameter, tricks)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;randomly select the batches in corpus, for each iteration, not ordering and sequencing, and this also saves some memory.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;why not use n-gram, window-based co-occurrence matrix, and this became sparse matrix
-&amp;gt; occupy so much bigger space, not that robust.
-&amp;gt; then what about other dimension reduction methods?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;(HW1)&lt;/strong&gt; SVD, factorize the matrix&amp;lt;/br&amp;gt;results: least square error in estimation
&lt;br /&gt;this way we can also make word-vectors&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;cant-we-approach-to-build-model-using-frequency---glove&quot;&gt;Can’t we approach to build model using frequency? - Glove&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Hacks to X (&lt;a href=&quot;https://www.semanticscholar.org/paper/An-Improved-Model-of-Semantic-Similarity-Based-on-Rohde-Plaut/73e6351a8fb61afc810a8bb3feaa44c41e5c5d7b&quot;&gt;Rohde et al. 2005&lt;/a&gt;)
&lt;br /&gt; student at CMU&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Remove too much frequent words which is function words&lt;/li&gt;
  &lt;li&gt;weigh more where it is closer&lt;/li&gt;
  &lt;li&gt;Use Pearson correlation instead of counts, then set negative values to 0&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;( And this techs were used in word2vec)&lt;/p&gt;

&lt;p&gt;Sort of direction in vector spaces matches the word’s feature, and below pic shows it matches with POS, in this case verb and noun&lt;/p&gt;

&lt;p&gt;And this is meaningful because this proved constructed VS does well in analogy.&lt;/p&gt;

&lt;p&gt;Conventional methods also can give you good vectors.&lt;/p&gt;

&lt;p&gt;And this could be the origin of &lt;code class=&quot;highlighter-rouge&quot;&gt;Glove&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Count based&lt;/strong&gt; vs &lt;strong&gt;direct based.&lt;/strong&gt;
&lt;br /&gt;&lt;em&gt;Direct based model&lt;/em&gt; goes sample by sample so that can’t use that well the statistics
&lt;br /&gt; On the other hand, &lt;em&gt;Count based model&lt;/em&gt;(usually classical model) can use stats more efficiently and also the memory.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Encoding meaning in vector differences (= fraction of log) Using co-occurence
&lt;br /&gt; &lt;strong&gt;Insight&lt;/strong&gt;: Ratio of co-occurrence probabilities can encode meaning components. (not enough just co-occurrence!)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Q.&lt;/em&gt;&lt;/strong&gt; How can we capture ratios of co-occurrence probabilities as linear meaning components in a word vector space?&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;Dot product should become similar as much as possible with log of co-occurrence&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/hy4kyit2a/f_auto,fl_lossy,q_70/learn/modules/glove-and-word-vectors-for-sentiment-analysis/use-glove-for-natural-language-processing/images/30c8354b6a239d6f0d9235189ce8d676_gloves-objective-function.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(#TODO1: check again, can’t understand)&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;how-to-evaluate-word-vectors&quot;&gt;How to evaluate word vectors?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;intrinsic vs extrinsic(use in real system(=real application) e.x. QA, web search…)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;intrinsic ex: calculate cosine, and see if it matches with language intuition&lt;/p&gt;

&lt;p&gt;(Tot. means analogy)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Comparing using hyper parameter (i.e., Vector dimensions, Window sizes)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/cs224n/evaluation-of-word2vec.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;if you only use context which is at one side, that is not as good as using both sided matrix (#TODO2: check the &lt;a href=&quot;https://nlp.stanford.edu/projects/glove/&quot;&gt;codes&lt;/a&gt;)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On the Dimensionality of Word Embedding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;mathy ideas using matrix perturbation idea.
&lt;br /&gt; =&amp;gt; if you increase dimensions, the performance gets flatten and they proved using perturbation theory (??)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;much time helps, and wikipedia is better than news data (1.6b wiki data is better than 4.3b of news data in web) when making word vectors&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WordSim353: Human judgement, which was from psycology&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;more-problem-regarding-word-senses-ambiguity-polysemy&quot;&gt;More problem regarding word senses (Ambiguity, Polysemy)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Most words have lots of meaning - ex. pike
    &lt;ul&gt;
      &lt;li&gt;common words&lt;/li&gt;
      &lt;li&gt;existed for a long time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Actually, this argument was existed when word2vec  came out, with labelling polysemy(multiple senses) and embeds it. (Huang et al. 2012), and cluster the departed words
&lt;br /&gt; =&amp;gt; but with this method, the senses are not that clear.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Linear Algebraic Structure of Word Senses, with Application to Polysemy (Arora, Ma, TACL2018)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WHY nlp people are mad at Word2Vec idea?&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;It came out that good word2vec directly related with subtask(extrinsic tasks) enhancement (like, name entity)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;see the paper of Sanjeev Arora’s group / ??? &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>dionne</name></author><summary type="html">Images: Vector directions related to word classes (Rohde et al. 2005)</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/cs224n/gate-l2.png" /></entry><entry><title type="html">CS224N: NLP with Deep Learning | Winter2019 | Lecture1</title><link href="http://localhost:4000/2020/05/cs224n-19w-course1/" rel="alternate" type="text/html" title="CS224N: NLP with Deep Learning | Winter2019 | Lecture1" /><published>2020-05-30T00:00:00+09:00</published><updated>2020-05-30T00:00:00+09:00</updated><id>http://localhost:4000/2020/05/cs224n-19w-course1</id><content type="html" xml:base="http://localhost:4000/2020/05/cs224n-19w-course1/">&lt;h1 id=&quot;introduction-and-word-vectors&quot;&gt;Introduction and Word Vectors&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;What is language?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Think about how complicated Human language is. - xkcd cartoon&lt;/p&gt;

&lt;p&gt;Considering the information theory, Human language is so slow&lt;/p&gt;

&lt;p&gt;Is the human language is just same with orangutan?&lt;/p&gt;

&lt;p&gt;Commonest linguistic way of thinking of meaning is a denotational meaning(see referential linguistics)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;with computer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But this definition is hard to implement with computer&lt;/p&gt;

&lt;p&gt;-&amp;gt; &lt;strong&gt;WordNet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;But wordnet is incomplete because it can’t handle with&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Traditional approach (a localist representation)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;treating each word as discrete symbols&lt;/strong&gt;: As categorical variable&lt;/p&gt;

&lt;p&gt;but with this approach, we can’t cover all of derivative.&lt;/p&gt;

&lt;p&gt;Moreover, &lt;strong&gt;relationship&lt;/strong&gt;  can’t be represented using localist representation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Distributional Semantics&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;J. R. Firth 1957&lt;/p&gt;

&lt;p&gt;Let’s see all of the examples of usage, and represent their appearance using dense vectors.&lt;/p&gt;

&lt;p&gt;the picture is just projects of 100-d vectors to 2-d (will talk about this later) / Be sure to keep in mind when you see the word-embeddings, there’s original vector space.&lt;/p&gt;

&lt;p&gt;Q. Are there standard features for i-th dimension in vector representation?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Word2vec&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mikolov paper&lt;/p&gt;

&lt;p&gt;vector representation is the only parameter with simple word2vec model(actually two)
1) center word vectors
2) context word vectors&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Objective function (changed little bit from likelihood)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1) Negative: minimize rather than maximize 
2) divide by size of corpus(T) i.e. scaling: make it independent of corpus size
3) log: turned out works well when you do things like optimization - it changes the objective function, which was originally was product, to sum&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Prediction function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;exp : makes number positive&lt;/p&gt;

&lt;p&gt;this function has two parts&lt;/p&gt;

&lt;p&gt;1) as doing the dot product, it calculates similarity (=relationship) between specific word(c) and context(o)
2) blue part means mapping from variable to probability distribution [^1]&lt;/p&gt;

&lt;p&gt;Q-&amp;gt;A: &lt;strong&gt;distributional&lt;/strong&gt; of meaning assumes we have intelligent vector which knows what word will be, when I give other words. so, we get high probability&lt;/p&gt;

&lt;p&gt;And notice a word has only one vector, regardless of the context. (since we have only one simple probability distribution)&lt;/p&gt;

&lt;p&gt;(explained formula / how to calculate)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;But be sure to you can calculate what’s happening in calculation process&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;we get this results, meaning we are sliding down the slope by
1) get a observed representation 
2) &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;jupyter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;stanford has lightweight version of glove&lt;/p&gt;

&lt;p&gt;disimilar could be useful, because this has multiple dimensions, so that each vector space has some feature, like women and man, and we can add/subtract that feature between word
-&amp;gt; makes us be able to do &lt;strong&gt;analogy&lt;/strong&gt;, using this semantic relationship.&lt;/p&gt;

&lt;p&gt;and this is foundation of modern distributed neural representations of words&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;this is a fourth declensions noun.&lt;/p&gt;

&lt;p&gt;So the plural of corpus is corpora.&lt;/p&gt;

&lt;p&gt;And whereas if you say&lt;/p&gt;

&lt;p&gt;core Pi everyone will know that you didn’t study Latin in high school.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;[^1]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;soft and max part&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;that’s sort of a hard max.&lt;/p&gt;

&lt;p&gt;Um, soft- this is a softmax because the exponenti- you know,&lt;/p&gt;

&lt;p&gt;if you sort of imagine this but- if we just ignore the problem&lt;/p&gt;

&lt;p&gt;negative numbers for a moment and you got rid of the exp, um,&lt;/p&gt;

&lt;p&gt;then you’d sort of coming out with&lt;/p&gt;

&lt;p&gt;a probability distribution but by and large it’s so be fairly&lt;/p&gt;

&lt;p&gt;flat and wouldn’t particularly pick out the max of&lt;/p&gt;

&lt;p&gt;the different XI numbers whereas when you exponentiate them,&lt;/p&gt;

&lt;p&gt;that sort of makes big numbers way bigger and so, this,&lt;/p&gt;

&lt;p&gt;this softmax sort of mainly puts mass where the max’s or the couple of max’s are.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;the context word and we’re subtracting from that what our model thinks um,&lt;/p&gt;

&lt;p&gt;the context should look like.&lt;/p&gt;

&lt;p&gt;What does the model think that the context should look like?&lt;/p&gt;

&lt;p&gt;This part here is formal in expectation.&lt;/p&gt;

&lt;p&gt;So, what you’re doing is you’re finding the weighted average&lt;/p&gt;

&lt;p&gt;of the models of the representations of each word,&lt;/p&gt;

&lt;p&gt;multiplied by the probability of it in the current model.&lt;/p&gt;

&lt;p&gt;So, this is sort of the expected context word according to our current model,&lt;/p&gt;

&lt;p&gt;and so we’re taking the difference between&lt;/p&gt;

&lt;p&gt;the expected context word and the actual context word that showed up,&lt;/p&gt;

&lt;p&gt;and that difference then turns out to exactly give&lt;/p&gt;

&lt;p&gt;us the slope as to which direction we should be&lt;/p&gt;

&lt;p&gt;walking changing the words&lt;/p&gt;

&lt;p&gt;representation in order to improve our model’s ability to predict.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;the observed representation of &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>dionne</name></author><summary type="html">Introduction and Word Vectors</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/cs224n/gate-l1.png" /></entry><entry><title type="html">fastai 2019 course-v3 Part1, lesson07</title><link href="http://localhost:4000/2020/04/v3-2019-lesson07-note/" rel="alternate" type="text/html" title="fastai 2019 course-v3 Part1, lesson07" /><published>2020-04-29T00:00:00+09:00</published><updated>2020-04-29T00:00:00+09:00</updated><id>http://localhost:4000/2020/04/v3-2019-lesson07-note</id><content type="html" xml:base="http://localhost:4000/2020/04/v3-2019-lesson07-note/">&lt;p&gt;Note of lesson7 : Deep Learning Part 1 of Spring 2019 at USF, version 3 course&lt;/p&gt;

&lt;p&gt;Today we will study lots of things so don’t be frustrated.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ResNets&lt;/li&gt;
  &lt;li&gt;Unets&lt;/li&gt;
  &lt;li&gt;GANs&lt;/li&gt;
  &lt;li&gt;RNNs&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 class=&quot;no_toc&quot; id=&quot;contents&quot;&gt;CONTENTS&lt;/h2&gt;

&lt;p&gt;@reshama at fastai forum, who deployed app using fastai both of ios and android version.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#lesson7-resnet-mnistipynb&quot; id=&quot;markdown-toc-lesson7-resnet-mnistipynb&quot;&gt;lesson7-resnet-mnist.ipynb&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#basic-cnn-with-batchnorm&quot; id=&quot;markdown-toc-basic-cnn-with-batchnorm&quot;&gt;Basic CNN with batchnorm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#refactor&quot; id=&quot;markdown-toc-refactor&quot;&gt;Refactor&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#resnet-ish&quot; id=&quot;markdown-toc-resnet-ish&quot;&gt;Resnet-ish&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lesson3-camvidipynb&quot; id=&quot;markdown-toc-lesson3-camvidipynb&quot;&gt;lesson3-camvid.ipynb&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lesson7-suprres-gan&quot; id=&quot;markdown-toc-lesson7-suprres-gan&quot;&gt;lesson7-suprres-gan&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#crappified-data&quot; id=&quot;markdown-toc-crappified-data&quot;&gt;Crappified data&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#gans&quot; id=&quot;markdown-toc-gans&quot;&gt;GANs&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#save-generated-images&quot; id=&quot;markdown-toc-save-generated-images&quot;&gt;Save generated images&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lesson7-wgan&quot; id=&quot;markdown-toc-lesson7-wgan&quot;&gt;lesson7-wgan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lesson7-superres&quot; id=&quot;markdown-toc-lesson7-superres&quot;&gt;lesson7-superres&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rnns&quot; id=&quot;markdown-toc-rnns&quot;&gt;RNNs&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#maintain-state&quot; id=&quot;markdown-toc-maintain-state&quot;&gt;maintain state&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nnrnn&quot; id=&quot;markdown-toc-nnrnn&quot;&gt;nn.RNN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-layer-gru&quot; id=&quot;markdown-toc-2-layer-gru&quot;&gt;2-layer GRU&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(#f) what do learn&lt;/p&gt;

&lt;h2 id=&quot;lesson7-resnet-mnistipynb&quot;&gt;&lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-resnet-mnist.ipynb&quot;&gt;lesson7-resnet-mnist.ipynb&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;data block API&lt;/p&gt;

&lt;p&gt;pillow’s convert mode &lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;, which is grey scale&lt;/p&gt;

&lt;p&gt;items attribute is kind of the thing we get from data&lt;/p&gt;

&lt;p&gt;binary color map, refer to matplotlib for more info&lt;/p&gt;

&lt;p&gt;remember that pytorch put channel first&lt;/p&gt;

&lt;p&gt;you have to say how to split (when using fastai lib)&lt;/p&gt;

&lt;p&gt;validation is (of course) has labels&lt;/p&gt;

&lt;p&gt;1) have itemlist 2) split it 3) label it&lt;/p&gt;

&lt;p&gt;y are category object for now mnist&lt;/p&gt;

&lt;p&gt;transforms&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;kind of digit, you don’t want to rotate or flip since it will change the digit’s meaning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So Jeremy added random crop and added padding&lt;/p&gt;

&lt;p&gt;[]: empty is transforms for validation set, no need for transform for validation set.&lt;/p&gt;

&lt;p&gt;we don’t use pre-trained model, so we don’t need image net stats. (#f)&lt;/p&gt;

&lt;p&gt;plot_multi can show you results of calling some function, which grab the dataset, how many transformed version we create?: infinite, each time we call it, we grab the new transformed dataset.&lt;/p&gt;

&lt;p&gt;(batch_size, channel, row, col)&lt;/p&gt;

&lt;h3 id=&quot;basic-cnn-with-batchnorm&quot;&gt;Basic CNN with batchnorm&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ni&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;how many channels you want? -&amp;gt; as much as you want&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(#f)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(1,8) -&amp;gt; one channel coming in,  &lt;code class=&quot;highlighter-rouge&quot;&gt;8&lt;/code&gt;: how many filters you want to come out&lt;/p&gt;

&lt;p&gt;conv(ni, nf) &amp;lt;- ni, nf is input / output channel&lt;/p&gt;

&lt;p&gt;so as a result, 10 by 1 by 1 (which means grid size is 1)&lt;/p&gt;

&lt;p&gt;careful of the comment, which represents grid size&lt;/p&gt;

&lt;p&gt;it decreases by half since &lt;code class=&quot;highlighter-rouge&quot;&gt;stride = 2&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;refactor&quot;&gt;Refactor&lt;/h3&gt;

&lt;p&gt;exactly the same neural net.&lt;/p&gt;

&lt;p&gt;how can we improve this?&lt;/p&gt;

&lt;h3 id=&quot;resnet-ish&quot;&gt;Resnet-ish&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;Deep Residual Learning for Image Recognition&lt;/a&gt; - skip connection, identity, res block&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Motivation of the paper: 56 layer is way more worse than the 20-layer(shallow) network.&lt;/li&gt;
  &lt;li&gt;Idea: keep the 56 layers but make results identical with shallow version&lt;/li&gt;
  &lt;li&gt;How: &lt;code class=&quot;highlighter-rouge&quot;&gt;a building block&lt;/code&gt;, every two convolutions, add the results together with input&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;and this became legendary architecture&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1712.09913&quot;&gt;Visualising the Loss Landscape of Neural Nets&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;x, y - weight space, y - loss&lt;/li&gt;
  &lt;li&gt;without identity connection, it’s very bumpy and with res connection, and this is little bit similar with batch norm.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;except the last one, jeremy added res block without last layer.&lt;/p&gt;

&lt;p&gt;don’t forget to refactor your code&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.9954&lt;/code&gt;, and NIPS 2015 the best paper was 0.45% error - sota changes so fast&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;MergeLayer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;SequentialEx : Sequential extended (#f)&lt;/p&gt;

&lt;p&gt;and real code, we don’t add, but &lt;code class=&quot;highlighter-rouge&quot;&gt;concat&lt;/code&gt;.  and this is &lt;strong&gt;dense net&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;memory intensive because how deep you go in, you have original data, but very little parameter (#q) (#f)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;really work well for segmentation&lt;/p&gt;

&lt;p&gt;(#f) re-building the modern architecture, and he keep trying to show …..(#f)&lt;/p&gt;

&lt;h2 id=&quot;lesson3-camvidipynb&quot;&gt;&lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid-tiramisu.ipynb&quot;&gt;lesson3-camvid.ipynb&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;in order to color cluster, it has to know what that it is&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.07285&quot;&gt;A guide to convolution arithmetic for deep learning&lt;/a&gt; - great picture show what does 3 by 3 half stride conv looks like.&lt;/p&gt;

&lt;p&gt;U-net, down sampling path. size keep decreasing, channels keep increasing. And at last the grid size came back to same.&lt;/p&gt;

&lt;p&gt;Then, how do we double the grid size?&lt;/p&gt;

&lt;p&gt;stride - half convolution -&amp;gt; transposed convolution, deconvolution,&lt;/p&gt;

&lt;p&gt;and this is maybe 1, 2 years ago.
why?&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;nearly all of the pixel is zero&lt;/li&gt;
  &lt;li&gt;different amount of information to the different convolution path (see the paper, and understand myself)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; (1) Nearest neighbour interpolation&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;just copy twice, no zero, no computation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(2) bilinear interpolation - weighted average (this is pretty standard with picture)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;/assets/images/lesson03-1.png&quot; /&gt; - kind of skip connection but not added to the every 2 conv block, but to the same stage of the downsampling to the same stage of the upsampling&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;see the code how fastai implemented this&lt;/p&gt;

&lt;p&gt;encoder refers to the downsampling part, which is substituted with resnet&lt;/p&gt;

&lt;p&gt;unet_block is connection between the up-sampling and down-sampling&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class UnetBlock
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;they grab the hook, to use resnet, and &lt;code class=&quot;highlighter-rouge&quot;&gt;up_out&lt;/code&gt; using up-sampling&lt;/p&gt;

&lt;p&gt;each time you see two convolutions like &lt;code class=&quot;highlighter-rouge&quot;&gt;conv2(conv1())&lt;/code&gt;, you can think of what if I add the res block? probably you would get a better results.&lt;/p&gt;

&lt;p&gt;identity connection is done with 1) add 2) concat&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;Q. why call concat before conv1, conv2 and not after? (#q - see the code) /  J: there’s no way to interact with channel (???) remember if you do 2 conv, it’s actually 3d, (#f)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Q. size of image feature layer changes, how does dense net work since it concatenate. / J: ?? (#f) 53:00:00&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lesson7-suprres-gan&quot;&gt;&lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb&quot;&gt;lesson7-suprres-gan&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;will use to another task, &lt;em&gt;image restoration&lt;/em&gt;, which starts from the image but will make &lt;em&gt;better&lt;/em&gt; image, like black-white to color, resolution, .. (#f)&lt;/p&gt;

&lt;h3 id=&quot;crappified-data&quot;&gt;Crappified data&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;paraLLeL(crappify, il.items)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fastai’s function which does crappification(it takes time quite much)&lt;/p&gt;

&lt;p&gt;we gonna use, pre-trained model, since we added some noise and we have to catch what original picture was., which is watermark removal&lt;/p&gt;

&lt;p&gt;use MESLoss, and it normally expects two vectors, which can compare so we flat version.&lt;/p&gt;

&lt;p&gt;pre-trained part of unet is down-sampling part.&lt;/p&gt;

&lt;h3 id=&quot;gans&quot;&gt;GANs&lt;/h3&gt;

&lt;p&gt;Motivation of GAN: Our loss function doesn’t represent what we want.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;we are missing the texture of pillow, blanket&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-&amp;gt; the emergent of GAN.
it uses another models(&lt;strong&gt;Critic, discriminator&lt;/strong&gt;) for loss function&lt;/p&gt;

&lt;p&gt;t = 3761 » Jeremy explaination of GAN&lt;/p&gt;

&lt;p&gt;cons: if you don’t have pre-trained Critic/Generator, it’s kind of blind vs blind&lt;/p&gt;

&lt;h3 id=&quot;save-generated-images&quot;&gt;Save generated images&lt;/h3&gt;

&lt;p&gt;let’s create Critics&lt;/p&gt;

&lt;p&gt;(#q) reconstruct = True&lt;/p&gt;

&lt;p&gt;we will learn more of what’s going on inside at part2&lt;/p&gt;

&lt;p&gt;if you don’t want to re-initiate the gpu ram, you can gc.collect() which will remove caching gpu.&lt;/p&gt;

&lt;p&gt;we will use Binary Cross Entropy but will not use resnot&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Because of weight could be increased much that we can’t handle that, but will learn at part2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;we should be careful when using gan, loss which uses adaptive loss&lt;/p&gt;

&lt;p&gt;we not only use the critic to loss function, but also MSE loss because if we use only the Critics as loss function, generator could make irrelevant photo of the original image.&lt;/p&gt;

&lt;p&gt;GANs hates momentum. - but nobody figured it out.&lt;/p&gt;

&lt;p&gt;tough things of training gan - loss number is meaningless. / so you have to see the results from time to time&lt;/p&gt;

&lt;p&gt;(original craffied picture / generated picture / original picture)&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;Q. What kind of task you will not use U-net? / J: Unet is used when size of output is aligned to the input. so any kind of generative modelling and segmentation is also generative modelling because we should out pixel segments which is responding to original pixel. and it would be absurd if we use unet to the classification, because we just need the down-sampling process.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lesson7-wgan&quot;&gt;&lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-wgan.ipynb&quot;&gt;lesson7-wgan&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;(skipped so fast…)&lt;/p&gt;

&lt;p&gt;interesting because we use bedrooms dataset&lt;/p&gt;

&lt;p&gt;the approach that we use is ‘can we create a bedroom?’&lt;/p&gt;

&lt;p&gt;we feed the generator &lt;strong&gt;random noise&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;and generator should return the de-noised bedroom.&lt;/p&gt;

&lt;h2 id=&quot;lesson7-superres&quot;&gt;&lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb&quot;&gt;lesson7-superres&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.08155&quot;&gt;Perceptual Losses for Real-Time Style Transfer and Super-Resolution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;doesn’t like the term ‘perceptual’ - jeremy prefers to say it is feature losses&lt;/p&gt;

&lt;p&gt;down-sampling part is called encoder, and vice versa&lt;/p&gt;

&lt;p&gt;same color represents same grid size&lt;/p&gt;

&lt;p&gt;(#f) explained idea but could not get. - &lt;em&gt;t=5022&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;pick the l1 loss or mse ( no matter)&lt;/p&gt;

&lt;p&gt;grad is false since we will use only the loss&lt;/p&gt;

&lt;p&gt;class featureloss is the implementation of the paper&lt;/p&gt;

&lt;p&gt;(abandoned to write -&amp;gt; too hard…. and too fast)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;upsize medium res data, and you can see the pixels enlarged focus.&lt;/p&gt;

&lt;p&gt;results is quite good&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jantic/DeOldify&quot;&gt;DeOldify&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the student of fast.ai, made colored picture who had the fast.ai course.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(#f) and also said lots of idea related to this. we can new way of Crappification.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;Q. how about using unet or gan to nlp, kind of generating shakespear’s novel. / J: possible, and it’s quite blue ocean, and will look thorough little bit at part2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Be sure not to understand at once, go through this at least 3 times or more&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;rnns&quot;&gt;&lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-human-numbers.ipynb&quot;&gt;RNNs&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;square - input / arrow - layer / circle - activation / triangle - output&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;go to the learn.summary and see the specifics&lt;/p&gt;

&lt;p&gt;we will do mat mul and non-linearity one(or more) more, but (??) will use same weight.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bptt&lt;/code&gt; - back prop through time&lt;/p&gt;

&lt;p&gt;13017 / 70 / bs - all dataset divide first  by batch size, and after that, divide by length limit (but why??????)&lt;/p&gt;

&lt;p&gt;every mini-batch joins up with previous mini-batch (that’s why he showed textify)&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;how we convert the diagram to the code&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;rnn is just a refactoring, there’s nothing new.&lt;/p&gt;

&lt;p&gt;-&amp;gt; but only just predicting last word is wasteful, so we will predict every word, which means just triangle comes inside the model.&lt;/p&gt;

&lt;h3 id=&quot;maintain-state&quot;&gt;maintain state&lt;/h3&gt;

&lt;p&gt;Let’s keep the hidden state.&lt;/p&gt;

&lt;p&gt;(rnn is totally normal nn but just refactored)&lt;/p&gt;

&lt;h3 id=&quot;nnrnn&quot;&gt;nn.RNN&lt;/h3&gt;

&lt;p&gt;this time we will render the output the other loop, which is &lt;code class=&quot;highlighter-rouge&quot;&gt;nn.RNN&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;bptt 20 means 20 layers of the diagram.&lt;/p&gt;

&lt;h3 id=&quot;2-layer-gru&quot;&gt;2-layer GRU&lt;/h3&gt;

&lt;p&gt;there are small nn which decide how much apply the nodes.&lt;/p&gt;

&lt;p&gt;GRU/lstm is depended on specifics&lt;/p&gt;</content><author><name>dionne</name></author><summary type="html">Note of lesson7 : Deep Learning Part 1 of Spring 2019 at USF, version 3 course</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/v3-l7densenet.png" /></entry><entry><title type="html">fastai 2020 course-v4 Part1, lesson07</title><link href="http://localhost:4000/2020/04/v4-2020-lesson07/" rel="alternate" type="text/html" title="fastai 2020 course-v4 Part1, lesson07" /><published>2020-04-29T00:00:00+09:00</published><updated>2020-04-29T00:00:00+09:00</updated><id>http://localhost:4000/2020/04/v4-2020-lesson07</id><content type="html" xml:base="http://localhost:4000/2020/04/v4-2020-lesson07/">&lt;p&gt;Note of lesson7 : &lt;a href=&quot;https://www.usfca.edu/data-institute/certificates/deep-learning-part-one&quot;&gt;Deep Learning Part 1 of Spring 2020 at USF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Today we will study&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Collaborative Filtering&lt;/li&gt;
  &lt;li&gt;Tabular modelling&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 class=&quot;no_toc&quot; id=&quot;contents&quot;&gt;CONTENTS&lt;/h2&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#collaborative-filtering&quot; id=&quot;markdown-toc-collaborative-filtering&quot;&gt;Collaborative Filtering&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#collaborative-filtering-from-scratch&quot; id=&quot;markdown-toc-collaborative-filtering-from-scratch&quot;&gt;Collaborative filtering from scratch&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#weight-decay&quot; id=&quot;markdown-toc-weight-decay&quot;&gt;Weight decay&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#creating-our-own-embedding-module&quot; id=&quot;markdown-toc-creating-our-own-embedding-module&quot;&gt;Creating our own Embedding module&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#interpreting-embeddings-and-biases&quot; id=&quot;markdown-toc-interpreting-embeddings-and-biases&quot;&gt;Interpreting embeddings and biases&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#using-fastaicollab&quot; id=&quot;markdown-toc-using-fastaicollab&quot;&gt;Using fastai.collab&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#embedding-distance&quot; id=&quot;markdown-toc-embedding-distance&quot;&gt;Embedding distance&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#boot-strapping-a-collaborative-filtering&quot; id=&quot;markdown-toc-boot-strapping-a-collaborative-filtering&quot;&gt;Boot strapping a collaborative filtering&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#deep-learning-for-collaborative-filtering&quot; id=&quot;markdown-toc-deep-learning-for-collaborative-filtering&quot;&gt;Deep Learning for collaborative filtering&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#sidebar-kwargs-and-delegates&quot; id=&quot;markdown-toc-sidebar-kwargs-and-delegates&quot;&gt;Sidebar: kwargs and delegates&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#end-sidebar&quot; id=&quot;markdown-toc-end-sidebar&quot;&gt;End sidebar&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#questionnaire&quot; id=&quot;markdown-toc-questionnaire&quot;&gt;Questionnaire&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tabular-modelling&quot; id=&quot;markdown-toc-tabular-modelling&quot;&gt;Tabular modelling&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#categorical-embeddings&quot; id=&quot;markdown-toc-categorical-embeddings&quot;&gt;Categorical embeddings&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#beyond-deep-learning&quot; id=&quot;markdown-toc-beyond-deep-learning&quot;&gt;Beyond Deep Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-dataset&quot; id=&quot;markdown-toc-the-dataset&quot;&gt;The dataset&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#kaggle-competitions&quot; id=&quot;markdown-toc-kaggle-competitions&quot;&gt;kaggle Competitions&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#look-at-the-data&quot; id=&quot;markdown-toc-look-at-the-data&quot;&gt;Look at the data&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#decision-trees&quot; id=&quot;markdown-toc-decision-trees&quot;&gt;Decision trees&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#handling-dates&quot; id=&quot;markdown-toc-handling-dates&quot;&gt;Handling dates&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#using-tabularpandas-and-tabularproc&quot; id=&quot;markdown-toc-using-tabularpandas-and-tabularproc&quot;&gt;Using TabularPandas and TabularProc&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#creating-the-decision-tree&quot; id=&quot;markdown-toc-creating-the-decision-tree&quot;&gt;Creating the decision tree&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#categorical-variables&quot; id=&quot;markdown-toc-categorical-variables&quot;&gt;Categorical variables&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#random-forests&quot; id=&quot;markdown-toc-random-forests&quot;&gt;Random forests&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#creating-a-random-forest&quot; id=&quot;markdown-toc-creating-a-random-forest&quot;&gt;Creating a random forest&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#out-of-bag-error&quot; id=&quot;markdown-toc-out-of-bag-error&quot;&gt;Out-of-bag error&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#model-interpretation&quot; id=&quot;markdown-toc-model-interpretation&quot;&gt;Model interpretation&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#tree-variance-for-prediction-confidence&quot; id=&quot;markdown-toc-tree-variance-for-prediction-confidence&quot;&gt;Tree variance for prediction confidence&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#feature-importance&quot; id=&quot;markdown-toc-feature-importance&quot;&gt;Feature importance&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#removing-low-importance-variables&quot; id=&quot;markdown-toc-removing-low-importance-variables&quot;&gt;Removing low-importance variables&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#removing-redundant-features&quot; id=&quot;markdown-toc-removing-redundant-features&quot;&gt;Removing redundant features&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#partical-dependence&quot; id=&quot;markdown-toc-partical-dependence&quot;&gt;Partical dependence&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#data-leakage&quot; id=&quot;markdown-toc-data-leakage&quot;&gt;Data leakage&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#tree-interpreter&quot; id=&quot;markdown-toc-tree-interpreter&quot;&gt;Tree interpreter&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#extrapolation-and-neural-networks&quot; id=&quot;markdown-toc-extrapolation-and-neural-networks&quot;&gt;Extrapolation and neural networks&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#finding-out-of-domain-data&quot; id=&quot;markdown-toc-finding-out-of-domain-data&quot;&gt;Finding out of domain data&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#using-a-neural-network&quot; id=&quot;markdown-toc-using-a-neural-network&quot;&gt;Using a neural network&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#sidebar-fastais-tabular-classes&quot; id=&quot;markdown-toc-sidebar-fastais-tabular-classes&quot;&gt;Sidebar: fastai’s Tabular classes&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#end-sidebar-1&quot; id=&quot;markdown-toc-end-sidebar-1&quot;&gt;End sidebar&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#ensembling&quot; id=&quot;markdown-toc-ensembling&quot;&gt;Ensembling&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#boosting&quot; id=&quot;markdown-toc-boosting&quot;&gt;Boosting&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#combining-embeddings-with-other-methods&quot; id=&quot;markdown-toc-combining-embeddings-with-other-methods&quot;&gt;Combining embeddings with other methods&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion-our-advice-for-tabular-modeling&quot; id=&quot;markdown-toc-conclusion-our-advice-for-tabular-modeling&quot;&gt;Conclusion: our advice for tabular modeling&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#questionnaire-1&quot; id=&quot;markdown-toc-questionnaire-1&quot;&gt;Questionnaire&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;collaborative-filtering&quot;&gt;Collaborative Filtering&lt;/h2&gt;

&lt;h3 id=&quot;collaborative-filtering-from-scratch&quot;&gt;Collaborative filtering from scratch&lt;/h3&gt;

&lt;p&gt;Last time issue: We are overfitting with just small batch&amp;lt;/br&amp;gt;
Capacity of model, normally reducing the parameter of model ends up very shallow model&lt;/p&gt;

&lt;h4 id=&quot;weight-decay&quot;&gt;Weight decay&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;a= 50&lt;/code&gt; means just small change will give you big results.&lt;/p&gt;

&lt;p&gt;(#f)&lt;/p&gt;

&lt;p&gt;weight decay means adding some valud to the gradients, so that it makes more shallow and less bumpy loss.&lt;/p&gt;

&lt;p&gt;Be cautious, when you do statistical model, they lessen the parameter to evade overfitting but modern machine learning doesn’t do that, and add regularization&lt;/p&gt;

&lt;h4 id=&quot;creating-our-own-embedding-module&quot;&gt;Creating our own Embedding module&lt;/h4&gt;

&lt;p&gt;Embedding is just indexing into an array&lt;/p&gt;

&lt;p&gt;Normally layer is made from inhertancing of module&lt;/p&gt;

&lt;p&gt;when you call torch and make tensor, they doesn’t have parameter, and you should define it using &lt;code class=&quot;highlighter-rouge&quot;&gt;nn.parameter&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DotProductBias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_factors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_bias&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_factors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_bias&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_range&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_range&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;pytorch has autograd so that we don’t have to calculate gradient manually&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What’s our advantage making our own embedding instead of using pytorch one
J: no advantage just implementing by yourself and easily learn concept.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;interpreting-embeddings-and-biases&quot;&gt;Interpreting embeddings and biases&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;movie_bias&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idxs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movie_bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'title'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idxs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;meaning of this, not just &lt;em&gt;(#f)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;we can use pca, and filter factors to 3, so we can select some kind of latent factors. &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h4 id=&quot;using-fastaicollab&quot;&gt;Using fastai.collab&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collab_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;you can get similar results using fastai&lt;/p&gt;

&lt;h4 id=&quot;embedding-distance&quot;&gt;Embedding distance&lt;/h4&gt;

&lt;p&gt;Distance between two movies.&lt;/p&gt;

&lt;p&gt;Let’s pick some movie and find distance, form one movie to every other movies.&lt;/p&gt;

&lt;p&gt;(#f)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(#f) J: visualization part is just what’s going in and..? sound quality is not good&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;boot-strapping-a-collaborative-filtering&quot;&gt;Boot strapping a collaborative filtering&lt;/h3&gt;

&lt;h3 id=&quot;deep-learning-for-collaborative-filtering&quot;&gt;Deep Learning for collaborative filtering&lt;/h3&gt;

&lt;p&gt;the other way to do collab, we can concatenate the embeddings&lt;/p&gt;

&lt;p&gt;(#q) can’t understand&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;get_emb_sz&lt;/code&gt; method, fast.ai will give you the layer’s tensor size&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collab_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;5e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;if you use params &lt;code class=&quot;highlighter-rouge&quot;&gt;use_nn=True&lt;/code&gt;, you can use concat version of collab&lt;/p&gt;

&lt;h4 id=&quot;sidebar-kwargs-and-delegates&quot;&gt;Sidebar: kwargs and delegates&lt;/h4&gt;

&lt;h4 id=&quot;end-sidebar&quot;&gt;End sidebar&lt;/h4&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;h3 id=&quot;questionnaire&quot;&gt;Questionnaire&lt;/h3&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tabular-modelling&quot;&gt;Tabular modelling&lt;/h2&gt;

&lt;h3 id=&quot;categorical-embeddings&quot;&gt;Categorical embeddings&lt;/h3&gt;

&lt;p&gt;It’s been a not much time that tabular data is used for deep learning model.&lt;/p&gt;

&lt;p&gt;Ex) German regions in embedding, if we draw embedding of the german city, it resembles actual german map&lt;/p&gt;

&lt;p&gt;many kinds of information of the world can be represented using embedding&lt;/p&gt;

&lt;p&gt;This is how google’s recommendation system works.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/google_collab.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;They use collab, which is concatenation of embeddingsgoogoo&lt;/p&gt;

&lt;h3 id=&quot;beyond-deep-learning&quot;&gt;Beyond Deep Learning&lt;/h3&gt;

&lt;p&gt;sometimes the other model, which is not deep learning models(classical model) do better than modern deep learning model&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Ensembles of decision trees (i.e. Random Forests and Gradient Boosting Machines), mainly for structured data (such as you might find in a database table at most companies)&lt;/li&gt;
  &lt;li&gt;Multi-layered neural networks learnt with SGD (i.e. shallow and/or deep learning), mainly for unstructured data (such as audio, vision, and natural language)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;try 1 first, and after that try 2.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;How the decision tree ensenble works?&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;we usually scikit-learn library.&lt;/p&gt;

&lt;p&gt;Refer &lt;a href=&quot;https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1491957662/ref=asap_bc?ie=UTF8&quot;&gt;this book&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;when you use y_range maximum as 5.5? J: because it uses sigmoid, which can’t reach to the max, min value &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Do you recommend real-time service using decision-tree? for my own experience it was too slow.
J:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;the-dataset&quot;&gt;The dataset&lt;/h3&gt;

&lt;h4 id=&quot;kaggle-competitions&quot;&gt;kaggle Competitions&lt;/h4&gt;

&lt;h4 id=&quot;look-at-the-data&quot;&gt;Look at the data&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;At this point, a good next step is to handle ordinal columns&lt;/code&gt; and in this case, it is size of the product. we can make it as a categorical variables&lt;/p&gt;

&lt;p&gt;Jeremy read &lt;a href=&quot;https://render.githubusercontent.com/view/ipynb?commit=5b70a64d66d0880977881cc589cebe38812550f8&amp;amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f356237306136346436366430383830393737383831636335383963656265333838313235353066382f30395f746162756c61722e6970796e62&amp;amp;nwo=fastai%2Ffastbook&amp;amp;path=09_tabular.ipynb&amp;amp;repository_id=243838973&amp;amp;repository_type=Repository#Decision-trees&quot;&gt;this part&lt;/a&gt;, this it when I do review&lt;/p&gt;

&lt;h3 id=&quot;decision-trees&quot;&gt;Decision trees&lt;/h3&gt;

&lt;p&gt;It doesn’t require you special coding skill&lt;/p&gt;

&lt;p&gt;This is some good example of feature engineering&lt;/p&gt;

&lt;h4 id=&quot;handling-dates&quot;&gt;Handling dates&lt;/h4&gt;

&lt;h4 id=&quot;using-tabularpandas-and-tabularproc&quot;&gt;Using TabularPandas and TabularProc&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TabularProc&lt;/code&gt; - Tabular process, which is in-place function.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Categorify&lt;/code&gt; - make column with a numeric value, which is same with we saw at vocab.&lt;/p&gt;

&lt;p&gt;And we should think about valiation, and at this case, making test set as random is not enough. because this is basically related to time.&lt;/p&gt;

&lt;p&gt;See how test set is divided, and we can set the validation set as future time data.&lt;/p&gt;

&lt;h4 id=&quot;creating-the-decision-tree&quot;&gt;Creating the decision tree&lt;/h4&gt;

&lt;p&gt;DecisionTree Regressor, something when we want to predict continuous variable.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Data augmentation for tabular data, do you have idea? J: Not sure, but will think about data semantics
unordered, and ordered category, does fast.ai distinguish between these? J: yes&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;you can use fastai function when drawing decision tree.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;draw_tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leaves_parallel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;look at diagram from top to bottom. it’s the best way.&lt;/p&gt;

&lt;p&gt;basic way to do regression is predict the average.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;leaf-node&lt;/strong&gt;: not further trees when it is &lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;if you want to train further, we can choice leaf-note number bigger&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;m_rmse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;means we made perfect model, but when we check validation model, it’s bigger than 0
	- one reason is related to leaf-node&lt;/p&gt;

&lt;p&gt;So we made our leaf-note to 25, and our result&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;do random tree (#f) ??&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;categorical-variables&quot;&gt;Categorical variables&lt;/h4&gt;

&lt;p&gt;related to categorical variables, we don’t have to do one-hot encode like using neural net! (we can make it, but there is no evidence it’s better)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;What can I do with categorical missing value? J: (#f)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;random-forests&quot;&gt;Random forests&lt;/h3&gt;

&lt;p&gt;(#q could not understand much)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.stat.berkeley.edu/~breiman/bagging.pdf&quot;&gt;bagging predictors&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;: “Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions… The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests… show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;random subset&lt;/code&gt;, when you average the error, it is zero???&lt;/p&gt;

&lt;p&gt;Also randomly choose the subset of columns&lt;/p&gt;

&lt;h4 id=&quot;creating-a-random-forest&quot;&gt;Creating a random forest&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200_000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;max_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_samples_leaf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RandomForestRegressor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;min_samples_leaf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min_samples_leaf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oob_score&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;in general, when you increase the &lt;code class=&quot;highlighter-rouge&quot;&gt;n_estimators&lt;/code&gt;, the accuracy enhances more&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;we can set up our own methods, to see what’s going on. you just picked first element of the result, and show them.&lt;/p&gt;

&lt;p&gt;but our evaluation get low. why?&lt;/p&gt;

&lt;h4 id=&quot;out-of-bag-error&quot;&gt;Out-of-bag error&lt;/h4&gt;

&lt;p&gt;it’s not about time set, we don’t need validation set to do it.&lt;/p&gt;

&lt;h3 id=&quot;model-interpretation&quot;&gt;Model interpretation&lt;/h3&gt;

&lt;h4 id=&quot;tree-variance-for-prediction-confidence&quot;&gt;Tree variance for prediction confidence&lt;/h4&gt;

&lt;p&gt;How confident are we in our predictions using a particular row of data?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;look at the standard deviation of the tree, how much did the tree were varied, and if we were very varied, it means we didn’t confident that much&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;feature-importance&quot;&gt;Feature importance&lt;/h4&gt;

&lt;p&gt;For predicting with a particular row of data, what were the most important factors, and how did they influence that prediction?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;m.feature_importance&lt;/code&gt; attribute&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;removing-low-importance-variables&quot;&gt;Removing low-importance variables&lt;/h4&gt;

&lt;p&gt;Which columns are the strongest predictors, which can we ignore?&lt;/p&gt;

&lt;p&gt;remove the ignorable tree, and re train, accuracy is about to same, but the number of feature decreased.
after&lt;/p&gt;

&lt;p&gt;before we had this much features&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/before.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It decreased!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/after.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;removing-redundant-features&quot;&gt;Removing redundant features&lt;/h4&gt;

&lt;p&gt;Which columns are effectively redundant with each other, for purposes of prediction?
How do predictions vary, as we vary these columns?&lt;/p&gt;

&lt;p&gt;in this way we can get simpler and simpler model, remaining the accuracy&lt;/p&gt;

&lt;h4 id=&quot;partical-dependence&quot;&gt;Partical dependence&lt;/h4&gt;

&lt;p&gt;best way is to draw histogram.&lt;/p&gt;

&lt;p&gt;we can draw depends on each label, and see parti&lt;/p&gt;

&lt;p&gt;what is said, how &lt;code class=&quot;highlighter-rouge&quot;&gt;YearMade&lt;/code&gt; impact sales, if all other valud is equal?&lt;/p&gt;

&lt;p&gt;What might be impact just mitigate specific variable?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/partial.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;is cluster doing something related to hierarchical J: yes&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;How to the feature importance values related to correlation? J: if you used to linear regression (#f) / Larry D. Here is an answer from Fra Pochetti: If 2 features are highly correlated their relative feature importance would be reduced compared to keeping just one of the two. Here why. A random forest selects features randomly at each split (in general). If 2 variables are correlated, they more or less carry the same signal wrt the dependent variable. Hence you can expect a tree to split on either of the 2 evenly. As an end result, your 2 features will have much less importance, just because they are carrying the same information. They hide each other. I generally remove correlated features even if it is not strictly needed, just to be able to uncover these kind of hidden relationships and spot truly important variables.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;data-leakage&quot;&gt;Data leakage&lt;/h4&gt;

&lt;h4 id=&quot;tree-interpreter&quot;&gt;Tree interpreter&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;treeinterpreter&lt;/code&gt; module&lt;/p&gt;

&lt;p&gt;So we take that one row of data, and put it through the first decision tree, looking to see what split is used at each point throughout the tree.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contributions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;extrapolation-and-neural-networks&quot;&gt;Extrapolation and neural networks&lt;/h3&gt;

&lt;p&gt;Jeremy usually index using special value ‘None’, not unsqeeze.&lt;/p&gt;

&lt;p&gt;random forest can’t extrapolate out side of train set, what it has seen, and this is big problem&lt;/p&gt;

&lt;h4 id=&quot;finding-out-of-domain-data&quot;&gt;Finding out of domain data&lt;/h4&gt;

&lt;p&gt;concatenating all of the independent variable,&lt;/p&gt;

&lt;p&gt;and ask is this data from training set or validation set?&lt;/p&gt;

&lt;p&gt;difference between valid data and train set,&lt;/p&gt;

&lt;p&gt;and extrapolation will not happen if it’s neural net.&lt;/p&gt;

&lt;h4 id=&quot;using-a-neural-network&quot;&gt;Using a neural network&lt;/h4&gt;

&lt;h4 id=&quot;sidebar-fastais-tabular-classes&quot;&gt;Sidebar: fastai’s Tabular classes&lt;/h4&gt;

&lt;p&gt;In fastai, a tabular model is simply a model which takes columns of continuous or categorical data, and predicts a category (a classification model) or a continuous value (a regression model). Categorical independent variables are passed through an embedding, and concatenated, as we saw in the neural net we used for collaborative filtering, and then continuous variables are concatenated as well.&lt;/p&gt;

&lt;h4 id=&quot;end-sidebar-1&quot;&gt;End sidebar&lt;/h4&gt;

&lt;h4 id=&quot;ensembling&quot;&gt;Ensembling&lt;/h4&gt;

&lt;p&gt;It’s simple we can just do average.&lt;/p&gt;

&lt;h4 id=&quot;boosting&quot;&gt;Boosting&lt;/h4&gt;

&lt;p&gt;another approach when we do ensemble,&lt;/p&gt;

&lt;p&gt;this is pretty sensitive to hyper-parameters&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;with tabular, dropping the feature is better than regularization? J: 
(#f) J:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;combining-embeddings-with-other-methods&quot;&gt;Combining embeddings with other methods&lt;/h4&gt;

&lt;p&gt;Entity embedding, which is &lt;code class=&quot;highlighter-rouge&quot;&gt;EE&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;conclusion-our-advice-for-tabular-modeling&quot;&gt;Conclusion: our advice for tabular modeling&lt;/h3&gt;

&lt;p&gt;slow regarding inference time, because they have to infer at every tree&lt;/p&gt;

&lt;h3 id=&quot;questionnaire-1&quot;&gt;Questionnaire&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;Jiwon, here is an answer from Jona R on the forum: Not certain, but I think that “0” was not actually a choice that users could rate. It seemed to me like it was used as a placeholder for “no rating” in some of Jeremy’s models.
That means that the lowest you would need to predict is “1”, which means that setting range 0 provides sufficient buffer.&lt;/p&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;wasn’t it 3d? how can we draw it using 2d drawing? &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;why it does not use minimum to minus? like [-0.5, 5.5] &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>dionne</name></author><summary type="html">Note of lesson7 : Deep Learning Part 1 of Spring 2020 at USF</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/wd.png" /></entry><entry><title type="html">fastai 2020 course-v4 Part1, lesson06</title><link href="http://localhost:4000/2020/04/v4-2020-lesson06/" rel="alternate" type="text/html" title="fastai 2020 course-v4 Part1, lesson06" /><published>2020-04-23T00:00:00+09:00</published><updated>2020-04-23T00:00:00+09:00</updated><id>http://localhost:4000/2020/04/v4-2020-lesson06</id><content type="html" xml:base="http://localhost:4000/2020/04/v4-2020-lesson06/">&lt;p&gt;Note of lesson6 : &lt;a href=&quot;https://www.usfca.edu/data-institute/certificates/deep-learning-part-one&quot;&gt;Deep Learning Part 1 of Spring 2020 at USF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Today we will study&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Image Classification&lt;/li&gt;
  &lt;li&gt;Multi-label classification&lt;/li&gt;
  &lt;li&gt;Collaborative filtering&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 class=&quot;no_toc&quot; id=&quot;contents&quot;&gt;CONTENTS&lt;/h2&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#image-classification&quot; id=&quot;markdown-toc-image-classification&quot;&gt;Image Classification&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#model-interpretation-course-link-book-link&quot; id=&quot;markdown-toc-model-interpretation-course-link-book-link&quot;&gt;Model Interpretation: Course link, Book link&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#improving-our-model&quot; id=&quot;markdown-toc-improving-our-model&quot;&gt;Improving our model&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#learning-rate-finder&quot; id=&quot;markdown-toc-learning-rate-finder&quot;&gt;Learning rate finder&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#unfreezing-and-transfer-learning&quot; id=&quot;markdown-toc-unfreezing-and-transfer-learning&quot;&gt;Unfreezing and transfer learning&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#discriminative-learning-rates&quot; id=&quot;markdown-toc-discriminative-learning-rates&quot;&gt;Discriminative learning rates&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#selecting-the-number-of-epochs&quot; id=&quot;markdown-toc-selecting-the-number-of-epochs&quot;&gt;Selecting the number of epochs&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#deeper-architectures&quot; id=&quot;markdown-toc-deeper-architectures&quot;&gt;Deeper architectures&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#assignment&quot; id=&quot;markdown-toc-assignment&quot;&gt;Assignment&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#multi-label-classification&quot; id=&quot;markdown-toc-multi-label-classification&quot;&gt;Multi-label classification&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#constructing-a-data-block&quot; id=&quot;markdown-toc-constructing-a-data-block&quot;&gt;Constructing a data block&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#binary-cross-entropy&quot; id=&quot;markdown-toc-binary-cross-entropy&quot;&gt;Binary cross entropy&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#regression&quot; id=&quot;markdown-toc-regression&quot;&gt;Regression&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#assemble-the-data&quot; id=&quot;markdown-toc-assemble-the-data&quot;&gt;Assemble the data&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#training-a-mode&quot; id=&quot;markdown-toc-training-a-mode&quot;&gt;Training a mode&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#assignment-1&quot; id=&quot;markdown-toc-assignment-1&quot;&gt;Assignment&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#collaborative-filtering&quot; id=&quot;markdown-toc-collaborative-filtering&quot;&gt;Collaborative filtering&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#learning-the-latent-factors&quot; id=&quot;markdown-toc-learning-the-latent-factors&quot;&gt;Learning the latent factors&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#creating-the-dataloaders&quot; id=&quot;markdown-toc-creating-the-dataloaders&quot;&gt;Creating the DataLoaders&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#collaborative-filtering-from-scratch&quot; id=&quot;markdown-toc-collaborative-filtering-from-scratch&quot;&gt;Collaborative filtering from scratch&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Previous; Recap of last class&lt;/p&gt;

&lt;h2 id=&quot;image-classification&quot;&gt;Image Classification&lt;/h2&gt;

&lt;h3 id=&quot;model-interpretation-course-link-book-link&quot;&gt;Model Interpretation: &lt;a href=&quot;https://render.githubusercontent.com/view/ipynb?commit=56ab576a6826ecea66ed555b3b46a90ed409bb19&amp;amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f636f757273652d76342f353661623537366136383236656365613636656435353562336234366139306564343039626231392f6e62732f30355f7065745f6272656564732e6970796e62&amp;amp;nwo=fastai%2Fcourse-v4&amp;amp;path=nbs%2F05_pet_breeds.ipynb&amp;amp;repository_id=248051827&amp;amp;repository_type=Repository#Model-Interpretation&quot;&gt;Course link&lt;/a&gt;, &lt;a href=&quot;https://render.githubusercontent.com/view/ipynb?commit=56ab576a6826ecea66ed555b3b46a90ed409bb19&amp;amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f636f757273652d76342f353661623537366136383236656365613636656435353562336234366139306564343039626231392f6e62732f30355f7065745f6272656564732e6970796e62&amp;amp;nwo=fastai%2Fcourse-v4&amp;amp;path=nbs%2F05_pet_breeds.ipynb&amp;amp;repository_id=248051827&amp;amp;repository_type=Repository#Model-Interpretation&quot;&gt;Book link&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;When you have many categories, use &lt;code class=&quot;highlighter-rouge&quot;&gt;most_confused()&lt;/code&gt; method rather than plotting confusion matrix &lt;sup id=&quot;fnref:q1&quot;&gt;&lt;a href=&quot;#fn:q1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;improving-our-model&quot;&gt;Improving our model&lt;/h3&gt;

&lt;h4 id=&quot;learning-rate-finder&quot;&gt;Learning rate finder&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;We can try to learn &lt;em&gt;fast&lt;/em&gt; which is done by epoch 1~2 and set learning rate big&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;learn.fine_tune()&lt;/code&gt; has &lt;code class=&quot;highlighter-rouge&quot;&gt;base_lr&lt;/code&gt; parameter&lt;/li&gt;
  &lt;li&gt;If learning rate is too high, loss validation gets too high compared to loss of train
    &lt;ul&gt;
      &lt;li&gt;why? because it diverges&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If learning rate is too small, train loss decreases too slowly, and there are much gap between train and valid loss. &lt;sup id=&quot;fnref:q2&quot;&gt;&lt;a href=&quot;#fn:q2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
    &lt;ul&gt;
      &lt;li&gt;So it will take long time, means too many epochs, resulting overfitting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;meaning of &lt;code class=&quot;highlighter-rouge&quot;&gt;learning rate &lt;/code&gt;~ &lt;code class=&quot;highlighter-rouge&quot;&gt;loss&lt;/code&gt; graph
    &lt;ul&gt;
      &lt;li&gt;find optimal lr drawing loss depends on learning rate&lt;/li&gt;
      &lt;li&gt;careful it’s logarithm scale&lt;/li&gt;
      &lt;li&gt;this method was invented at 15 and before that people just experimented&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;lr_find()&lt;/code&gt; goes through one sing mini-batch?
J: no, it’s just working through data-loader, and diff is we try many lrs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;why steepest? why not minimum?
J: at the minimum we don’t learn anymore. we want our model to enhance learning while training &lt;br /&gt; R: About lr_find(), it’s natural that it seems too simple&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;unfreezing-and-transfer-learning&quot;&gt;Unfreezing and transfer learning&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;we throw away last layer, and re-train depends on our data/task&lt;/li&gt;
  &lt;li&gt;And the below function is easy way when we do just fine-tune&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;learn.find_tune??
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;calling &lt;code class=&quot;highlighter-rouge&quot;&gt;cnn_learner&lt;/code&gt; freeze our model, so don’t have to do it separately&lt;/li&gt;
  &lt;li&gt;But when you do unfreeze, which means you train all the params, you need to adjust the learning rate more.&lt;/li&gt;
  &lt;li&gt;We can do better because we just used the same learning rate for a whole training&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;discriminative-learning-rates&quot;&gt;Discriminative learning rates&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/discriminative_lr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;use &lt;code class=&quot;highlighter-rouge&quot;&gt;slice&lt;/code&gt; at lr_max parameter means discriminative learning rate &lt;sup id=&quot;fnref:q4&quot;&gt;&lt;a href=&quot;#fn:q4&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;selecting-the-number-of-epochs&quot;&gt;Selecting the number of epochs&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If you choose too big epoch, valid_loss will not change from specific point, and this is related to &lt;code class=&quot;highlighter-rouge&quot;&gt;fit_one_cycle&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;What &lt;code class=&quot;highlighter-rouge&quot;&gt;fit_one_cycle&lt;/code&gt; does?
    &lt;ul&gt;
      &lt;li&gt;different from just &lt;code class=&quot;highlighter-rouge&quot;&gt;fit&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;start purposely from low learning rate. and from the point of highest point, they decrease lr again&lt;/li&gt;
      &lt;li&gt;if error_rate stop from specific epoch, use that epoch as epoch and do it again&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Loss is just a thing we want to approximate, so always care &lt;code class=&quot;highlighter-rouge&quot;&gt;error&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;deeper-architectures&quot;&gt;Deeper architectures&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;It would be possible that you don’t want pre-trained but usually it’s helpful&lt;/li&gt;
  &lt;li&gt;usually out of memory happens
    &lt;ul&gt;
      &lt;li&gt;about, &lt;code class=&quot;highlighter-rouge&quot;&gt;.to_fp16()&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;half precision floating point&lt;/code&gt;, NVIDIA GPU support special tensor and it’s faster about 2x/3x&lt;/li&gt;
      &lt;li&gt;you can use this using module &lt;code class=&quot;highlighter-rouge&quot;&gt;from fastai2.callback.fp16 import *&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Try a small model before scaling up the model &amp;lt; because bigger model doesn’t guarantee better performance&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;assignment&quot;&gt;Assignment&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Don’t forget the questionnaire&lt;/li&gt;
  &lt;li&gt;Read paper, &lt;a href=&quot;https://arxiv.org/abs/1506.01186&quot;&gt;Cyclical Learning Rates for Training Neural Networks&lt;/a&gt; and see how you can get best results with adjusting learning rate, find out best learning rate by yourself!
    &lt;ul&gt;
      &lt;li&gt;of course you can see fast.ai learning rate source code&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;How do you know you can do better?
J: you don’t know, who knows. just try and experiment&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;about &lt;code class=&quot;highlighter-rouge&quot;&gt;.to_fp16()&lt;/code&gt; it doesn’t affect result?
J: less bumpy, little bit better but not that big deal&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;question about random
J: not does machine learning but  deep learning specifically. For more info, see Rachael’s Linear Algebra course.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;multi-label-classification&quot;&gt;Multi-label classification&lt;/h2&gt;

&lt;h3 id=&quot;constructing-a-data-block&quot;&gt;Constructing a data block&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;pandas, which is for dataframe
    &lt;ul&gt;
      &lt;li&gt;when you slicing, &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; is always optional&lt;/li&gt;
      &lt;li&gt;Read &lt;code class=&quot;highlighter-rouge&quot;&gt;Python for Data Analysis&lt;/code&gt; class written by person who made pandas&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;dataset is abstract idea of class
    &lt;ul&gt;
      &lt;li&gt;If you get &lt;em&gt;index&lt;/em&gt;, and &lt;em&gt;length&lt;/em&gt;, it’s dataset.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;string.ascii_lowercase&lt;/code&gt; is qualified dataset since it has length and index&lt;/li&gt;
      &lt;li&gt;If you index it mostly get tuple, independent variable and dependent variable.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Datasets is usually composed of not stack of data and label
    &lt;ul&gt;
      &lt;li&gt;fast.ai, we implemented use file name as independent variable, and through function we get dependent variable&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dataloader divides Datasets to batches, &lt;a href=&quot;https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&amp;amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30365f6d756c74696361742e6970796e62&amp;amp;nwo=fastai%2Ffastbook&amp;amp;path=06_multicat.ipynb&amp;amp;repository_id=243838973&amp;amp;repository_type=Repository#Constructing-a-data-block&quot;&gt;read the book&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Datablock assumes basically we have 2 kind of variable
    &lt;ul&gt;
      &lt;li&gt;randomly select different validation set so we have different output whenever we call dataset&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
                   get_x = get_x, get_y = get_y)
dsets = dblock.datasets(df)
dsets.train[0]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
(PILImage mode=RGB size=500x375,
 TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PILImage mode=RGB size=500x375&lt;/code&gt;: independent variable, which is a input
    &lt;ul&gt;
      &lt;li&gt;we did transform filename to tensors&lt;/li&gt;
      &lt;li&gt;output is one-hot encoding&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Shouldn’t it be an integer but why output(&lt;code class=&quot;highlighter-rouge&quot;&gt;TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))&lt;/code&gt;) is float?
J: because we &lt;em&gt;will&lt;/em&gt; use cross-entropy style loss, which does floating calculation&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;why we don’t use with floating point 8 bit?
J: could be fast, but low precision (but maybe possible)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;binary-cross-entropy&quot;&gt;Binary cross entropy&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resnet18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;activs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;activs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;you can try grapping the one batch of the data to the model, you can get an output.
    &lt;ul&gt;
      &lt;li&gt;Use a&lt;code class=&quot;highlighter-rouge&quot;&gt;dls.train.one_batch()&lt;/code&gt; function to ensure what’s going in and out&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;binary_cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;result is 0 to 1 but we get a variable between 0 and 1 so that we use sigmoid&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;same reason as we said at softmax, normally we use &lt;code class=&quot;highlighter-rouge&quot;&gt;log &lt;/code&gt; (fast and acurate)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;explained &lt;a href=&quot;https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&amp;amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30365f6d756c74696361742e6970796e62&amp;amp;nwo=fastai%2Ffastbook&amp;amp;path=06_multicat.ipynb&amp;amp;repository_id=243838973&amp;amp;repository_type=Repository#Binary-cross-entropy&quot;&gt;the book&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;One-hot encoded target, use &lt;code class=&quot;highlighter-rouge&quot;&gt;BCELoss&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;accuracy as a metric only works for single label dataset
    &lt;ul&gt;
      &lt;li&gt;because accuracy does &lt;code class=&quot;highlighter-rouge&quot;&gt;argmax&lt;/code&gt; which chooses largest number&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;so doing multi-categorical problem, use metrics which can compare each activation with some threshold(not selecting one value), and pass if the number over threshold
    &lt;ul&gt;
      &lt;li&gt;but we might want to change threshold depends on the input, so that we use &lt;code class=&quot;highlighter-rouge&quot;&gt;partial function&lt;/code&gt; which sets default variable, and change if we want&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;the accuracy changes if I use different threshold
    &lt;ul&gt;
      &lt;li&gt;How can I get &lt;em&gt;best&lt;/em&gt; threshold?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;accs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy_multi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresh&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;we can plot and select the best number and don’t have to care of overfitting (because it’s not that bumpy as rule of thumb)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;regression&quot;&gt;&lt;a href=&quot;https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&amp;amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30365f6d756c74696361742e6970796e62&amp;amp;nwo=fastai%2Ffastbook&amp;amp;path=06_multicat.ipynb&amp;amp;repository_id=243838973&amp;amp;repository_type=Repository#Regression&quot;&gt;Regression&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;two types of task at supervised learning 1) classification(discrete variable) 2) regression(continuous variable)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;assemble-the-data&quot;&gt;Assemble the data&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;get_image_files&lt;/code&gt; gather image recursively&lt;/li&gt;
  &lt;li&gt;here, it important to setting evaluation to a specific person using&lt;code class=&quot;highlighter-rouge&quot;&gt;splitter&lt;/code&gt;, not randomly selection -&amp;gt; it’s continuous frame, so if you just select random data, it would be overestimated.&lt;/li&gt;
  &lt;li&gt;pytorch has tensor &lt;code class=&quot;highlighter-rouge&quot;&gt;batch&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;channel&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;height&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;width&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;regarding channel, image has 3 channels
    &lt;ul&gt;
      &lt;li&gt;you can see the version of &lt;code class=&quot;highlighter-rouge&quot;&gt;R&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;G&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;B&lt;/code&gt; using the below code&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;im&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image2tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'image/grizzly.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;im&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Reds'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Greens'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Blues'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;show_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;can we give multi-channel bigger than 3?
J: yes, it used often like when you use satellite image. But your pre-trained model is usually for a 3-channel and fastai handles that case, but is is just problem of axis&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;training-a-mode&quot;&gt;Training a mode&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ds_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;left of output is target, right is prediction&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Notice&lt;/em&gt;  It’s interesting that basically our pre-trained model was trained for classification task. But it works well when you do regression
    &lt;ul&gt;
      &lt;li&gt;why? pre-trained model from ImageNet is collection of image’s features like, objects, color, texture, shadow and so on&lt;/li&gt;
      &lt;li&gt;so from pre-trained model, we can get the &lt;em&gt;features&lt;/em&gt; of an image, and do the &lt;em&gt;other job&lt;/em&gt;(e.g., regression) with fine-tuning&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;assignment-1&quot;&gt;Assignment&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;go to the bear classifier, and find out when you give image which is not included in label and see what happens.  change model from single labelling to multi-labelling, and tell what happened at fastai forum&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;at traditional machine learning we used cross-validation, we don’t use it at deep learning?
J: First, nowadays cross-validations are less common(if not on kaggle, because praction of data is important), because cross-validation was used there were not lots of data. Second, cross-validation is not related selection between machine learning and deep learning&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;CF algorithm used other than recommendation system
J: whatever it’s kind of recommendation system, if concept is finding out the other candidates using the previous behaviour&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;how can i make data set if I have video? how split?(time phrase)
J: like full color movie, rank-5 tensor by (time, h, w, batch, channel). but usually it would be 4 tensor, because of size of tensor or key problem, but theoretically possible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;collaborative-filtering&quot;&gt;&lt;a href=&quot;https://render.githubusercontent.com/view/ipynb?commit=b7f3f0d750196e155de05b0788725a352faa7732&amp;amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6661737461692f66617374626f6f6b2f623766336630643735303139366531353564653035623037383837323561333532666161373733322f30385f636f6c6c61622e6970796e62&amp;amp;nwo=fastai%2Ffastbook&amp;amp;path=08_collab.ipynb&amp;amp;repository_id=243838973&amp;amp;repository_type=Repository#Collaborative-filtering-deep-dive&quot;&gt;Collaborative filtering&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;empty part means user didn’t watch or rate the movie&lt;/li&gt;
  &lt;li&gt;upper and below part represent same info&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/pic1-v4-L6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;learning-the-latent-factors&quot;&gt;Learning the latent factors&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CF algorithm is related to &lt;em&gt;latent&lt;/em&gt;  variable(;factors) since we don’t have &lt;em&gt;a label explaining/depicting properties&lt;/em&gt; which made you choose specific movie
    &lt;ul&gt;
      &lt;li&gt;In other words, there is no specific label how we could predict the dependent variable(recommendation; movies user didn’t watch) results from independent var(rating regarding user and movie)&lt;/li&gt;
      &lt;li&gt;but we can assume it has labels like genres and make matrix representing it&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;randomly create user’s factor(;latent, hidden) and movie’s factor. and do matrix multiplication with those, which is dot product.&lt;/li&gt;
  &lt;li&gt;and sum it and compare with target, so that you can learn parameters, which were randomly initialized&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;creating-the-dataloaders&quot;&gt;Creating the DataLoaders&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Let’s make DataLoaders using basic python and PyTorch!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;user and movie is represented using index, label,..,called &lt;em&gt;look up in an index&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;but this is problem, because DL treats only kind of matrix multiplication.&lt;/li&gt;
      &lt;li&gt;so that we make one-hot encoding matrix&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;And this is quite amazing because it came out with any kind of discrete value, we can make it work using arrays&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;how is different when you treat actual data between dense and sparse data?
J: we will not treat sparse data, but there’s course Rachael’s linear algebra&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;embedding layer: multiplying by a one hot encoded matrix, using the computational shortcut that it can be implemented by simply indexing directly.
    &lt;ul&gt;
      &lt;li&gt;there is excel explaining detailed computation&lt;/li&gt;
      &lt;li&gt;This is important because usually people think embedding is something difficult, but it’s just computational shortcut to do matrix multiplication&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;collaborative-filtering-from-scratch&quot;&gt;Collaborative filtering from scratch&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;importance of dunder method of python. (like &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt;)
    &lt;ul&gt;
      &lt;li&gt;explained OOP concept&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Inheritance of python, which used DotProduct class
    &lt;ul&gt;
      &lt;li&gt;Module is fast.ai version of pytorch’s nn.Module&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;forward&lt;/code&gt;function grab embedding, using specific index
    &lt;ul&gt;
      &lt;li&gt;(again) Remember Embedding is just kind of shortcut to make a one-hot encoding matrix&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DotProduct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_factors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_factors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movie_factors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;users&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;64: size of mini_batch, 2: index&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x,y = dls.one_batch()
x.shape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.Size([64, 2])&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We use bias to represent specific character of &lt;em&gt;each user&lt;/em&gt; and &lt;em&gt;movie&lt;/em&gt;, because embedding of user/movie doesn’t show users’ character, who might generally doesn’t like movie&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;what should we do when my model is overfitting very quickly with small epoch&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;i.e., what should we do to evade overfitting and don’t want to lessen epoch?&lt;/li&gt;
      &lt;li&gt;augmentation can be one solution but we can’t do augmentation with this data&lt;/li&gt;
      &lt;li&gt;in this case, we do other regularization, which means panellize the fast learning &lt;sup id=&quot;fnref:q5&quot;&gt;&lt;a href=&quot;#fn:q5&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Collaborative filtering algorithm works better than svd or kind of that?
J: yes&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;My Questions&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:q1&quot;&gt;
      &lt;p&gt;no way to see with regression model? &lt;a href=&quot;#fnref:q1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:q2&quot;&gt;
      &lt;p&gt;But how do I know if loss decreases slowly or not? &lt;a href=&quot;#fnref:q2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:q4&quot;&gt;
      &lt;p&gt;I need to study more of scheduled learning &lt;a href=&quot;#fnref:q4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:q5&quot;&gt;
      &lt;p&gt;Isn’t there any side effects when you did too much regularization? &lt;a href=&quot;#fnref:q5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>dionne</name></author><summary type="html">Note of lesson6 : Deep Learning Part 1 of Spring 2020 at USF</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/lesson6-v4.png" /></entry><entry><title type="html">fastai 2019 course-v3 Part1, lesson06</title><link href="http://localhost:4000/2020/04/v3-2019-lesson06-note/" rel="alternate" type="text/html" title="fastai 2019 course-v3 Part1, lesson06" /><published>2020-04-15T00:00:00+09:00</published><updated>2020-04-15T00:00:00+09:00</updated><id>http://localhost:4000/2020/04/v3-2019-lesson06-note</id><content type="html" xml:base="http://localhost:4000/2020/04/v3-2019-lesson06-note/">&lt;h1 id=&quot;lesson-06&quot;&gt;Lesson 06&lt;/h1&gt;

&lt;p&gt;Will find official notes &lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/files/dl-2019/notes/notes-1-6.md&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;rossmanntabular&quot;&gt;Rossmann(Tabular)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Tabular data: be careful on Categorical variable vs Continuous variable.&lt;/li&gt;
  &lt;li&gt;if datatype is int, fastai think it is classification, not a regression.&lt;/li&gt;
  &lt;li&gt;Root mean square percentage error. as loss function.&lt;/li&gt;
  &lt;li&gt;When you assign the y_range, it’s better to assign little bit more than actual maximum. &amp;gt; because it’s sigmoid.&lt;/li&gt;
  &lt;li&gt;Intermediate layers, which is weight matrix is 1) 1000, and 2) 500 -&amp;gt; which means our parameter would be 500*1000.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;what-is-dropout-and-embedding-dropout&quot;&gt;What is dropout and embedding dropout?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://jmlr.org/papers/v15/srivastava14a.html&quot;&gt;Nitish Srivastava, Dropout: A Simple way to prevent Neural Networks from Overfitting&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;you can dropout with &lt;code class=&quot;highlighter-rouge&quot;&gt;p&lt;/code&gt; value, make it specified to specific layer, or make it applied to all the layers.&lt;/li&gt;
  &lt;li&gt;Pytorch code 1) bernoulli, which decides whether you will hold it? 2) and divide the noise value depends on noise value. so noise became 2 or remain 0.
    &lt;ul&gt;
      &lt;li&gt;According to pytorch code, We do change at training time, but we do nothing at test time. and this means you don’t have to do anything special with inference time.’&lt;/li&gt;
      &lt;li&gt;&lt;b&gt;TODO&lt;/b&gt;: find at forums &lt;code class=&quot;highlighter-rouge&quot;&gt;what is inference time&lt;/code&gt; - Related to NVIDIA, GPU.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Embedding dropout is just a dropout.
    &lt;ul&gt;
      &lt;li&gt;It’s different between continuous variable and embedding layer.  &lt;b&gt;TODO&lt;/b&gt; Still can’t understand. why embedding dropout is effective. or,… in need.&lt;/li&gt;
      &lt;li&gt;Let’s delete at random, some of the results of the embedding.&lt;/li&gt;
      &lt;li&gt;and It worked well especially at Kaggle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1502.03167.pdf&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt; -&amp;gt; came out false! According to &lt;a href=&quot;https://arxiv.org/pdf/1805.11604.pdf&quot;&gt;How Does Batch Normalization Help Optimization?&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The key was  &lt;code class=&quot;highlighter-rouge&quot;&gt;multiplicative&lt;/code&gt; bias &lt;em&gt;gamma&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;additive&lt;/code&gt; bias &lt;em&gt;beta&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Explain
    &lt;ul&gt;
      &lt;li&gt;Let $$ \hat{y}  = f(w_1, w_2, w_3, … , x) $$ ,  loss = MSE , Then &lt;code class=&quot;highlighter-rouge&quot;&gt;y_range&lt;/code&gt; should be between 1 and 5&lt;/li&gt;
      &lt;li&gt;And Activation function ends with &lt;code class=&quot;highlighter-rouge&quot;&gt;-1 -&amp;gt; +1&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;To mitigate this problem, we can add another parameter, like $$w_n$$&lt;/li&gt;
      &lt;li&gt;But there’re so much interactions in the process so just re-scale the output.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;momentum-parameter-at-batchnorm1d&quot;&gt;Momentum parameter at BatchNorm1d&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Different from momentum like in optimization.&lt;/li&gt;
  &lt;li&gt;This momentum is Exponentially weighted moving average of the mean, instead of deviation.
    &lt;ul&gt;
      &lt;li&gt;If this is small number: &lt;code class=&quot;highlighter-rouge&quot;&gt;mean standard deviation&lt;/code&gt; would be less from mini_batch to mini_batch » less regularization effect. (If this is large number, variation would be greater from mini_batch to mini_batch » more regularization effect)&lt;/li&gt;
      &lt;li&gt;TODO: can’t sure, but i understand, this is not about &lt;code class=&quot;highlighter-rouge&quot;&gt;how to update parameter&lt;/code&gt; but about &lt;code class=&quot;highlighter-rouge&quot;&gt;how much reflect previous value when scale and shift&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Q. Preference between batchnorm and the other regularizations(drop out, weight decay)&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;A. Nope, always try and see the results&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lesson6-pets-moreipynb&quot;&gt;lesson6-pets-more.ipynb&lt;/h2&gt;

&lt;h3 id=&quot;data-augmentation&quot;&gt;Data Augmentation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Last reg&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;get_transforms&lt;/code&gt; has lots of params (even not yet learned all) -&amp;gt; check documentation
    &lt;ul&gt;
      &lt;li&gt;Remember you can implement all the doc contents bc it’s made from nbdev&lt;/li&gt;
      &lt;li&gt;TODO: try this!!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Essence of data augmentation is you should maintain the label, while somewhat making sense.
    &lt;ul&gt;
      &lt;li&gt;ex) tilt, because it’s optically sensible, you can always change the angle of the data view.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;zeros, border, and reflection but always &lt;code class=&quot;highlighter-rouge&quot;&gt;reflection&lt;/code&gt; works most of the time, so that is the default&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;convolutional-kernelwhat-is-convolution&quot;&gt;Convolutional Kernel(What is convolution?)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Will make heat_map from scratch, which means the parts convolution focuses on&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/setosa_visualization.png&quot; alt=&quot;setosa_visualization&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;http://setosa.io/ev/image-kernels/
    &lt;ul&gt;
      &lt;li&gt;javascript thing&lt;/li&gt;
      &lt;li&gt;How convolution works&lt;/li&gt;
      &lt;li&gt;Kernel. which does element-wise multiplication, and sum them up&lt;/li&gt;
      &lt;li&gt;so it has on pixel less at borders -&amp;gt; so it uses padding, and fastai uses reflection as said.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;why this Kernel(matrix) helps catching horizontal edge side?
    &lt;ul&gt;
      &lt;li&gt;because below kernel weights differently, depends on &lt;code class=&quot;highlighter-rouge&quot;&gt;x axis&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;why familiar, because it’s similar intuition with Zeiler/Fergus &lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;Visualizing and Understanding Convolutional Networks&lt;/a&gt; paper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/matrix-kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c&quot;&gt;CNN from different viewpoints&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;output of pixel is results from different linear equations.&lt;/li&gt;
      &lt;li&gt;If you connect this with represents of neural network nodes, you can see that the specific inp nodes connected with specific out nodes.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Summarize&lt;/strong&gt;: cnn does 1) matmul some of the elements are always zero 2) same weight for every row, which is called &lt;code class=&quot;highlighter-rouge&quot;&gt;weight time? weight..?, 1:18:50&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;(picture)&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;further-lowdown&quot;&gt;Further lowdown&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Because generally image has 3  channels, we need rank 3 kernel.&lt;/li&gt;
  &lt;li&gt;And &lt;strong&gt;do multiply with all channel output is one pixel&lt;/strong&gt;.(&lt;code class=&quot;highlighter-rouge&quot;&gt;draw by your self&lt;/code&gt;)
    &lt;ul&gt;
      &lt;li&gt;but this kernel will catch one feature, like horizontal, so that we make more kernel so that output becomes (h * w * kernel)&lt;/li&gt;
      &lt;li&gt;And that &lt;code class=&quot;highlighter-rouge&quot;&gt;kernel&lt;/code&gt; come to &lt;code class=&quot;highlighter-rouge&quot;&gt;channel&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stride 2 conv&lt;/strong&gt;: with 3 by 3 kernel, stride 2 conv -&amp;gt; (h/2 * w/2 * kernel) &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
    &lt;ul&gt;
      &lt;li&gt;skip or jump over input pixel&lt;/li&gt;
      &lt;li&gt;to protect from memory out of control&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;TODO: understand yourself the blocks of conv-kernel:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Usually use big kernel size at first layer (will study this at part2) &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;Bottom&amp;amp;right highlighting kernel, since that parts are positive numbers&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;k = tensor([
    [0.  ,-5/3,1],
    [-5/3,-5/3,1],
    [1.  ,1   ,1],
]).expand(1,3,3,3)/6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Why divided by 6, when doing expand? : &lt;a href=&quot;https://forums.fast.ai/t/lesson-6-in-class-discussion/31440/353?u=spellonyou&quot;&gt;forum answer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.tensor.expand&lt;/code&gt;: for memory efficient, because we should do RGB&lt;/li&gt;
  &lt;li&gt;We do not make separate kernel, but make rank 4 kernel
    &lt;ul&gt;
      &lt;li&gt;4d tensor is just stacked kernel&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;t[None].shape&lt;/code&gt; create new unit axis, and why? we make this -&amp;gt; it should move unit of batch, not one size image.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;average-pooling-feature&quot;&gt;Average pooling, feature&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;suppose our pre-trained model results in size of &lt;code class=&quot;highlighter-rouge&quot;&gt;11 by 11 by 512 &lt;/code&gt; and my classification task has 37 classes
    &lt;ul&gt;
      &lt;li&gt;take the first face of channel, which is 11 by 11 and &lt;code class=&quot;highlighter-rouge&quot;&gt;mean&lt;/code&gt; it, so that make rank 2 tensor, 512 by 1&lt;/li&gt;
      &lt;li&gt;and make 2d matrix, which is 512 by 37 and multiply so that we can get 37 by 1 matrix.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Feature, at convolution block
    &lt;ul&gt;
      &lt;li&gt;So, when we transfer-learning without unfreeze, every element of last matrix (512 by 1) should represent(or could catch) each feature.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heatmap-hook&quot;&gt;Heatmap, Hook&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/heatmap.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hook_output(model[0]) -&amp;gt; acts -&amp;gt; avg_acts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;if we average the block with &lt;code class=&quot;highlighter-rouge&quot;&gt;axis=feature&lt;/code&gt;, result of matrix(11 by 11) depicts &lt;code class=&quot;highlighter-rouge&quot;&gt;how activated was that area?&lt;/code&gt; -&amp;gt; it is heatmap, &lt;code class=&quot;highlighter-rouge&quot;&gt;avg_acts&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;and acts comes from hook, which is more advanced pytorch feature.
    &lt;ul&gt;
      &lt;li&gt;hook into pytorch machine itself, and run any arbitrary Pytorch code&lt;/li&gt;
      &lt;li&gt;Why this is cool?: Normally it gives set of outputs of forward pass, but we can interrupt and hook the forward pass.&lt;/li&gt;
      &lt;li&gt;Also can store the output of the convolutional part of the model, which is before avg_pooling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Thinking back when we do cut off &lt;code class=&quot;highlighter-rouge&quot;&gt;after&lt;/code&gt; the conv part.
    &lt;ul&gt;
      &lt;li&gt;but with fast.ai the original convolutional part of the model would be &lt;em&gt;the first thing in the model&lt;/em&gt;, specifically could be given from &lt;code class=&quot;highlighter-rouge&quot;&gt;learn.model.eval()[0]&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;And this is gotten from &lt;code class=&quot;highlighter-rouge&quot;&gt;hooked_output&lt;/code&gt; and having hooked the output, we can pass our x_minibatch to output.&lt;/li&gt;
      &lt;li&gt;Not directly, but with normalized, minibatch, put on to the gpu&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;one_item()&lt;/code&gt; function do it, when we have one data &lt;code class=&quot;highlighter-rouge&quot;&gt;TODO: this is assignment&lt;/code&gt; do it yourself without one_item function&lt;/li&gt;
      &lt;li&gt;and &lt;code class=&quot;highlighter-rouge&quot;&gt;.cuda()&lt;/code&gt; put it on gpu&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;you should print out very often the shape of tensor, and try think why.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;(personal) Further research&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Yes, as notes of official course, the ConvNN have become more and more important for other ML model but computer vision. (see &lt;a href=&quot;https://arxiv.org/pdf/1807.06521.pdf&quot;&gt;Convolutional Block Attention Module&lt;/a&gt; relationship paper) and nlp is much more fall behind of computer vision at modern deep learning research, less augmentation method, resource optimization, performance(even not comparable, they both has standard task), … &lt;strong&gt;SO&lt;/strong&gt; How about enhance nlp model using this (kind of) relationship?&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Footnote&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;what is conv1d, conv2d, conv3d? &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;why use comparatively huge kernel at first layer? &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>dionne</name></author><summary type="html">Lesson 06</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/att_00069.png" /></entry><entry><title type="html">[Q&amp;amp;A] Image Segmentation, using Unet with Driving Video data</title><link href="http://localhost:4000/2020/04/qna-image-segmentation/" rel="alternate" type="text/html" title="[Q&amp;A] Image Segmentation, using Unet with Driving Video data" /><published>2020-04-02T00:00:00+09:00</published><updated>2020-04-02T00:00:00+09:00</updated><id>http://localhost:4000/2020/04/qna-image-segmentation</id><content type="html" xml:base="http://localhost:4000/2020/04/qna-image-segmentation/">&lt;p&gt;This post is about my questions while I was studying &lt;a href=&quot;https://www.usfca.edu/data-institute/certificates/deep-learning-part-one&quot;&gt;USF Deep Learning course&lt;/a&gt; about image segmentation task.&lt;br /&gt;
All the answers are from the course, source code, library document, or document. &lt;br /&gt;
I cared about being clear at reporting information including source of information, however if there are still anything unclear, please contact me.&lt;/p&gt;

&lt;p&gt;And thank you Jeremy&amp;amp;Rachael for everything. Also Thank you Cambridge Computer Vision Lab to made us to study with your labor.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The Cambridge-driving Labeled Video Database (CamVid) is the first collection of videos with object class semantic labels, complete with metadata. The database provides ground truth labels that associate each pixel with one of 32 semantic classes.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;If someone is interested in this project, please check &lt;a href=&quot;http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/&quot;&gt;the site&lt;/a&gt; and see the details.&lt;/p&gt;

&lt;p&gt;Now, let’s start first using jupyter’s one of tricks which I love most. It enables cell to print the code without print function.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;IPython.core.interactiveshell&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InteractiveShell&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# pretty print all cell's output and not just the last one
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InteractiveShell&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ast_node_interactivity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;all&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fastai.vision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fastai.callbacks.hooks&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fastai.utils.mem&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;untar_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URLs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CAMVID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# The locations where the data and models are downloaded are set in config.yml
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I’m trying to accustomed to using &lt;code class=&quot;highlighter-rouge&quot;&gt;pathlib&lt;/code&gt; module, not just it became built-in module in python, but I felt uncomfortable myself with os module. However, still unpredictable conflicts are remain, even in the quite standard library like Pytorch, tensorflow, onnx.(it require me string for path. not PosixPath. will send PR..)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[PosixPath('/root/.fastai/data/camvid/valid.txt'),
 PosixPath('/root/.fastai/data/camvid/images'),
 PosixPath('/root/.fastai/data/camvid/labels'),
 PosixPath('/root/.fastai/data/camvid/codes.txt')]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;path_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'images'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;path_lbl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'labels'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fnames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_image_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#filename
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lbl_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_image_files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path_lbl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;1play-with-data-my-hypothesis&quot;&gt;1.(Play with data) My Hypothesis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;File name has &lt;code class=&quot;highlighter-rouge&quot;&gt;A_B&lt;/code&gt; format. and A / B would be at key-value position.&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;collections - defaultdict&lt;/code&gt;
    &lt;h3 id=&quot;default-dict-link&quot;&gt;Default Dict: &lt;a href=&quot;https://docs.python.org/3.8/library/collections.html#defaultdict-objects&quot;&gt;Link&lt;/a&gt;&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;easy to group a sequence of key and value pairs into a dictionary of list?&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lbl_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(PosixPath('/root/.fastai/data/camvid/images/0001TP_009210.png'),
 PosixPath('/root/.fastai/data/camvid/labels/0016E5_01800_P.png'))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lbl_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'0001TP'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;124
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0001TP ['009210', '008850', '007350', '008970', '009840', '010140', '008490', '008520', '009540', '008250', '008340', '006840', '007860', '007410', '007740', '009870', '010080', '007890', '008790', '010020', '008400', '007080', '008280', '010380', '009330', '009060', '007470', '006810', '009720', '008580', '007110', '008730', '009150', '007680', '009780', '007800', '007290', '008760', '009510', '008640', '008310', '007440', '006900', '007500', '008460', '009030', '008130', '009480', '009900', '010230', '009270', '008040', '007590', '007950', '009990', '008550', '007260', '008100', '007530', '006960', '008190', '009420', '009930', '009000', '007830', '008940', '006690', '009570', '008880', '010170', '007560', '009300', '006750', '009360', '010200', '007320', '008010', '009120', '007620', '007200', '007140', '010320', '006720', '008670', '007230', '008370', '010260', '009690', '006930', '009090', '007770', '010290', '010350', '008610', '008070', '009600', '008430', '009450', '007380', '009240', '007710', '007170', '008160', '008910', '007020', '006780', '007050', '009960', '009810', '008220', '009180', '009750', '010050', '009660', '010110', '007920', '009630', '007650', '006990', '008700', '009390', '007980', '008820', '006870']
0016E5 ['01290', '08159', '05760', '08133', '08063', '06660', '00960', '05850', '00750', '06960', '08035', '08107', '07975', '08017', '05610', '07140', '08119', '08027', '07170', '08400', '08093', '02100', '06390', '04470', '08340', '06060', '00600', '07470', '08151', '07800', '01620', '05730', '01530', '00690', '08430', '05940', '01980', '07320', '08069', '07965', '04380', '05430', '01410', '06780', '08007', '08087', '08079', '06600', '08109', '05490', '00901', '04590', '04680', '08045', '01770', '06690', '08085', '06810', '00420', '08011', '07440', '02190', '06300', '04800', '01500', '00450', '08029', '01470', '06330', '07997', '08067', '05370', '08013', '08190', '00840', '02370', '08049', '08135', '01440', '06870', '05820', '05280', '08051', '04440', '08091', '01380', '00630', '07290', '05520', '04770', '00540', '07995', '07999', '05550', '07920', '08101', '08141', '08053', '04620', '08103', '05160', '07350', '08057', '06030', '06000', '08550', '07963', '08089', '05970', '08047', '05640', '06240', '05220', '04350', '01590', '07959', '01950', '08117', '06180', '01560', '05400', '08043', '07680', '00780', '08081', '07050', '01020', '01350', '04530', '06720', '07969', '08149', '08003', '08131', '08129', '08033', '05460', '01650', '07530', '08023', '05340', '08640', '05100', '08075', '01230', '04980', '02070', '01080', '06210', '05910', '08009', '01800', '05190', '02400', '08083', '08019', '07620', '07200', '07890', '08059', '06990', '04410', '08121', '08123', '06930', '08137', '08147', '08095', '06570', '06150', '08153', '06840', '05250', '00510', '08370', '08580', '08113', '07410', '08097', '01200', '04950', '07770', '07650', '04710', '06090', '08055', '07110', '07981', '00990', '08250', '08127', '01920', '07985', '08220', '08005', '08157', '05130', '08071', '01140', '04830', '07740', '08143', '06120', '02040', '08111', '08115', '00660', '08280', '06420', '07983', '02220', '05700', '01860', '01260', '04920', '06510', '07020', '08073', '08105', '08125', '06360', '07860', '07993', '00810', '06540', '08099', '08139', '02010', '07973', '08155', '07991', '06630', '00480', '06750', '04890', '08001', '08025', '00870', '08490', '01830', '07977', '05010', '01170', '07961', '01680', '01050', '07987', '07080', '04560', '00930', '05310', '02340', '05790', '08460', '00720', '08031', '02280', '08039', '08037', '08065', '06270', '08077', '06900', '04650', '06480', '07230', '08041', '06450', '00570', '07989', '04740', '07979', '02250', '07380', '00390', '01710', '07590', '08021', '08520', '07500', '01110', '04500', '02310', '07971', '02130', '05580', '05880', '08610', '08310', '08145', '05670', '04860', '07260', '08015', '07967', '01740', '01320', '07560', '07830', '01890', '08061', '02160', '07710', '05070', '05040']
Seq05VD ['f00030', 'f02550', 'f03450', 'f01110', 'f00480', 'f00210', 'f04590', 'f04170', 'f01800', 'f03990', 'f03360', 'f03900', 'f02070', 'f00810', 'f03690', 'f01350', 'f01530', 'f04980', 'f05100', 'f03060', 'f00900', 'f03870', 'f02460', 'f01470', 'f02370', 'f02820', 'f04080', 'f02760', 'f04860', 'f02250', 'f04200', 'f00270', 'f03720', 'f02850', 'f04410', 'f01200', 'f03090', 'f02010', 'f03930', 'f00090', 'f01650', 'f01890', 'f03840', 'f03030', 'f02130', 'f01230', 'f04110', 'f02520', 'f04140', 'f04020', 'f00060', 'f03420', 'f01560', 'f00120', 'f04290', 'f02340', 'f00300', 'f01380', 'f00870', 'f01860', 'f02970', 'f04560', 'f02730', 'f00330', 'f04530', 'f03780', 'f01770', 'f03390', 'f05040', 'f02430', 'f03330', 'f00660', 'f01740', 'f02100', 'f04800', 'f04050', 'f00510', 'f02790', 'f04350', 'f00690', 'f00540', 'f02490', 'f00960', 'f00930', 'f04230', 'f02880', 'f03600', 'f01020', 'f01500', 'f02400', 'f04830', 'f04470', 'f03300', 'f02670', 'f00450', 'f01980', 'f01170', 'f01620', 'f04500', 'f01080', 'f03180', 'f05070', 'f03150', 'f04950', 'f01440', 'f03510', 'f01710', 'f00360', 'f04770', 'f02910', 'f01050', 'f00630', 'f04320', 'f00570', 'f03240', 'f02190', 'f01140', 'f03540', 'f02220', 'f02640', 'f03960', 'f00000', 'f04920', 'f01950', 'f00990', 'f03480', 'f03000', 'f00420', 'f04620', 'f03210', 'f00780', 'f03570', 'f01590', 'f00750', 'f01920', 'f04650', 'f03750', 'f03630', 'f02310', 'f02610', 'f02580', 'f04740', 'f02280', 'f04680', 'f00390', 'f00720', 'f03660', 'f02040', 'f03270', 'f00180', 'f03810', 'f01410', 'f01290', 'f03120', 'f00840', 'f04440', 'f00150', 'f01260', 'f02700', 'f02940', 'f00600', 'f01830', 'f04260', 'f05010', 'f04890', 'f02160', 'f00240', 'f04380', 'f01680', 'f04710', 'f01320']
0006R0 ['f02820', 'f03690', 'f03180', 'f02550', 'f01020', 'f03660', 'f02340', 'f01170', 'f02610', 'f02940', 'f01290', 'f02100', 'f01350', 'f03270', 'f03870', 'f01380', 'f01980', 'f03810', 'f02430', 'f02310', 'f01830', 'f03480', 'f02970', 'f01890', 'f03210', 'f03930', 'f02040', 'f02070', 'f02400', 'f01560', 'f03030', 'f01770', 'f01590', 'f01950', 'f03420', 'f01650', 'f03450', 'f00990', 'f03630', 'f01500', 'f03570', 'f00930', 'f03090', 'f03360', 'f02880', 'f02460', 'f01440', 'f01920', 'f01230', 'f03840', 'f02730', 'f01620', 'f02220', 'f03750', 'f03330', 'f03540', 'f02520', 'f02790', 'f01050', 'f03120', 'f01800', 'f01140', 'f01860', 'f01530', 'f01470', 'f02670', 'f02490', 'f01260', 'f01110', 'f02760', 'f01680', 'f03150', 'f02580', 'f03300', 'f02280', 'f01200', 'f03390', 'f03510', 'f02640', 'f02190', 'f02370', 'f01320', 'f02130', 'f03600', 'f03240', 'f03780', 'f03720', 'f02700', 'f01410', 'f01080', 'f02850', 'f01710', 'f03900', 'f03060', 'f01740', 'f02010', 'f02250', 'f00960', 'f03000', 'f02160', 'f02910']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0001TP 124
0016E5 305
Seq05VD 171
0006R0 101
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0016E5 305
0001TP 124
0006R0 101
Seq05VD 171
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(('0001TP', '009210'), ('0016E5', '01800'))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2my-question-link&quot;&gt;2.My question: &lt;a href=&quot;https://docs.fast.ai/vision.image.html#ImageSegment&quot;&gt;Link&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Why do we need masking? and does color from fastai library? (have to look into source code)&lt;/li&gt;
  &lt;li&gt;What do the parameter alpha do?&lt;/li&gt;
  &lt;li&gt;When people make masked img, would it be have ranged integer limit?&lt;/li&gt;
  &lt;li&gt;Does image normalization related with this?&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lbl_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lbl_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f_sorted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lbl_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lbl_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;33&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;33&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lbl_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lbl_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# img.show(ax=axs[0], y=mask, title='masked')
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;output_21_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;img_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# img.show(ax=axs[0], y=mask, title='masked')
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'4'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;output_22_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;open_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lbl_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;torch.Size([1, 720, 960])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;open_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lbl_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;torch.Size([1, 720, 960])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;open_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;torch.Size([3, 720, 960])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;open_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;torch.Size([3, 720, 960])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#labeled data
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tensor([[[0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         [0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         [0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         ...,
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176],
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176],
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176]],

        [[0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         [0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         [0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         ...,
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176],
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176],
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176]],

        [[0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         [0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         [0.0157, 0.0157, 0.0157,  ..., 0.0824, 0.0824, 0.0824],
         ...,
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176],
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176],
         [0.0667, 0.0667, 0.0667,  ..., 0.1176, 0.1176, 0.1176]]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# after mask, labeled data
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tensor([[[ 4,  4,  4,  ..., 21, 21, 21],
         [ 4,  4,  4,  ..., 21, 21, 21],
         [ 4,  4,  4,  ..., 21, 21, 21],
         ...,
         [17, 17, 17,  ..., 30, 30, 30],
         [17, 17, 17,  ..., 30, 30, 30],
         [17, 17, 17,  ..., 30, 30, 30]]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;img_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(tensor([[[0.0706, 0.0667, 0.0706,  ..., 0.6431, 0.6549, 0.6627],
          [0.0745, 0.0706, 0.0706,  ..., 0.6431, 0.6510, 0.6549],
          [0.0784, 0.0706, 0.0745,  ..., 0.6392, 0.6588, 0.6588],
          ...,
          [0.0863, 0.0824, 0.0824,  ..., 0.1333, 0.1216, 0.1255],
          [0.0902, 0.0863, 0.0824,  ..., 0.1255, 0.1176, 0.1216],
          [0.0863, 0.0824, 0.0784,  ..., 0.1137, 0.1059, 0.1137]],
 
         [[0.0706, 0.0667, 0.0706,  ..., 0.7490, 0.7608, 0.7686],
          [0.0745, 0.0706, 0.0706,  ..., 0.7451, 0.7569, 0.7608],
          [0.0784, 0.0706, 0.0745,  ..., 0.7412, 0.7529, 0.7529],
          ...,
          [0.0980, 0.0941, 0.0941,  ..., 0.1804, 0.1686, 0.1725],
          [0.1059, 0.1020, 0.0980,  ..., 0.1725, 0.1647, 0.1686],
          [0.1020, 0.0980, 0.0941,  ..., 0.1608, 0.1529, 0.1608]],
 
         [[0.0784, 0.0745, 0.0784,  ..., 0.7569, 0.7686, 0.7765],
          [0.0824, 0.0784, 0.0784,  ..., 0.7647, 0.7647, 0.7686],
          [0.0784, 0.0706, 0.0745,  ..., 0.7608, 0.7647, 0.7647],
          ...,
          [0.1216, 0.1176, 0.1176,  ..., 0.2000, 0.1882, 0.1922],
          [0.1176, 0.1137, 0.1098,  ..., 0.1843, 0.1765, 0.1804],
          [0.1137, 0.1098, 0.1059,  ..., 0.1725, 0.1647, 0.1725]]]),
 tensor([[[ 18,  17,  18,  ..., 183, 186, 188],
          [ 19,  18,  18,  ..., 183, 185, 186],
          [ 20,  18,  19,  ..., 182, 185, 185],
          ...,
          [ 25,  24,  24,  ...,  43,  40,  41],
          [ 26,  25,  24,  ...,  41,  39,  40],
          [ 25,  24,  23,  ...,  38,  36,  38]]]))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3what-is-a-difference-between-image-and-imagesegment&quot;&gt;3.What is a difference between image and imageSegment?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.fast.ai/vision.image.html#ImageSegment&quot;&gt;imageSegment&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An ImageSegment object has the same properties as an Image. The only difference is that when applying the transformations to an ImageSegment, it will ignore the functions that deal with lighting and keep values of 0 and 1.&lt;/li&gt;
  &lt;li&gt;It’s easy to show the segmentation mask over the associated Image by using the y argument of show_image.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lbl_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'no mask'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'masked'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#seg mask over the img using y arg
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mask only'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;output_31_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.fast.ai/vision.image.html#ImageSegment&quot;&gt;vision.image&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;##4.Why/How img div by 255 and how it results&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.fast.ai/vision.image.html#open_image&quot;&gt;fast.ai : vision.image&lt;/a&gt; - If div=True, pixel values are divided by 255. to become floats between 0. and 1.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;At times, you want to get rid of distortions caused by lights and shadows in an image.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Normalizing the RGB values of an image can at times be a simple and effective way of achieving this.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;So sum of the pixel’s value over all channels(which is &lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt;) divides each intensified channel so that nomalized value will be &lt;code class=&quot;highlighter-rouge&quot;&gt;R/S&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;G/S&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;B/S&lt;/code&gt; (where, S=R+G+B).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aishack.in/tutorials/normalized-rgb/&quot;&gt;Detailed explain here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-python-evaluation-order&quot;&gt;4. Python &lt;a href=&quot;https://docs.python.org/3/reference/expressions.html#evaluation-order&quot;&gt;Evaluation Order&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Python evaluates expressions from left to right. Notice that while evaluating an assignment, the right-hand side is evaluated before the left-hand side.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mask_tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trg_tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void_tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask_tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trg_tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void_tmp&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trg_tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void_tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# (1) target is not same with void
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;True 1 10
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Example 1
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(2, 3)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Example 2
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(2, 4)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-model-learner-parameter--pct_start&quot;&gt;5. model learner parameter :: pct_start&lt;/h2&gt;

&lt;p&gt;A: Percentage of total number of epochs when learning rate rises during one cycle.
Q: Sorry, I still confused that one cycle in the new API only runs one epoch. How the percentage of total number of epochs works? Can you give a example? If learn.fit_one_cycle(10, slice(1e-4,1e-3,1e-2), pct_start=0.05)??
A: Ok, strictly correct answer would be percentage of iterations, so you can have lr both increase and decrease during same epoch. In your example, say, you have 100 iterations per epoch, then for half an epoch (0.05 * (10 * 100) = 50) lr will rise, then slowly decrease.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Q2: Thanks for this explanation … so essentially, it is the percentage of overall iterations where the LR is increasing, correct?&lt;/p&gt;

&lt;p&gt;So, given the default of 0.3, it means that your LR is going up for 30% of your iterations and then decreasing over the last 70%.&lt;/p&gt;

&lt;p&gt;Is that a correct summation of what is happening?&lt;/p&gt;

&lt;p&gt;A2: Yes, I think that’s correct.&lt;/p&gt;

&lt;p&gt;You can verify that by changing its value and check:
learn.recorder.plot_lr()&lt;/p&gt;

&lt;p&gt;For example if pct_start = 0.2&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;attachment:ScreenClip.png&quot; alt=&quot;ScreenClip.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&quot;https://forums.fast.ai/t/what-is-the-pct-start-mean/26168/10&quot;&gt;forums.fastai&lt;/a&gt;&lt;/p&gt;</content><author><name>dionne</name></author><category term="featured" /><summary type="html">This post is about my questions while I was studying USF Deep Learning course about image segmentation task. All the answers are from the course, source code, library document, or document. I cared about being clear at reporting information including source of information, however if there are still anything unclear, please contact me.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/output_31_0.png" /></entry><entry><title type="html">SGD from scratch</title><link href="http://localhost:4000/2020/03/SGD-from-scratch/" rel="alternate" type="text/html" title="SGD from scratch" /><published>2020-03-20T00:00:00+09:00</published><updated>2020-03-20T00:00:00+09:00</updated><id>http://localhost:4000/2020/03/SGD-from-scratch</id><content type="html" xml:base="http://localhost:4000/2020/03/SGD-from-scratch/">&lt;h2 id=&quot;stochastic-gradient-descent-from-scratch&quot;&gt;Stochastic Gradient Descent from scratch&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Tensor means array
    &lt;ul&gt;
      &lt;li&gt;2D tensor means matrix&lt;/li&gt;
      &lt;li&gt;row * height * col&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;rank&lt;/em&gt; - how many dimensions / axes are there&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/ccMHJeQU4Qw?t=4302&quot;&gt;Resnet34 is just a function&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;Y=aX+b
    &lt;ul&gt;
      &lt;li&gt;Y = a_1 X_1 + a_2 X_2 (X_2=1)&lt;/li&gt;
      &lt;li&gt;a: coefficient(a_1: slope, a_2: intercept)&lt;/li&gt;
      &lt;li&gt;X: parameter&lt;/li&gt;
      &lt;li&gt;This is dot product - two thing multiplied and added&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Optimization
    &lt;ul&gt;
      &lt;li&gt;loss.backward(): calculate the gradient&lt;/li&gt;
      &lt;li&gt;a.sub_(lr * a.grad): take coefficient a, and substract gradient and multiply with learning rate, and substitute the value&lt;/li&gt;
      &lt;li&gt;How gradient is calculated: &lt;a href=&quot;https://explained.ai/matrix-calculus/index.html&quot;&gt;The matrix calculus you need for deep learning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;with torch.no_grad(): # turn gradient calculation off when you do sgd update&lt;/li&gt;
  &lt;li&gt;at the real code, we make batch size, and slice some matrix (ex: y[:rand_idx]) and update the value.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Recap the terminology&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Learning rate: a thing that we multiply our gradient by, to decide how much to update the weights by&lt;/li&gt;
  &lt;li&gt;Epoch: one complete run through all of our data points(highly related to overfitting)&lt;/li&gt;
  &lt;li&gt;minibatch: random bunch of points that you use to update your weights&lt;/li&gt;
  &lt;li&gt;SGD: gradient descent using minibatch&lt;/li&gt;
  &lt;li&gt;Model / Architecture: kind of mean same thing. Architecture is the mathematical function that you’re fitting the parameters to.&lt;/li&gt;
  &lt;li&gt;Parameter: Also known as coefficients, and also known as weights, are the number that you are updating.&lt;/li&gt;
  &lt;li&gt;Loss function: the thing that’s telling you how far away or how close you are to correct answer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bonus note&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;When I was going to draw the prediction value, I got this error&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;---------------------------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;RuntimeError&lt;/span&gt;                              &lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;58&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1650&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cee19828&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;----&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frames&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;python3&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;.6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;packages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__array__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;484&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__array__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;485&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;--&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;486&lt;/span&gt;             &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;487&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;488&lt;/span&gt;             &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;RuntimeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Can&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'t call numpy() on Variable that requires grad. Use var.detach().numpy() instead.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Regarding to &lt;a href=&quot;https://discuss.pytorch.org/t/cant-call-numpy-on-variable-that-requires-grad/20763&quot;&gt;pytorch forum&lt;/a&gt;, When I try to scatter it, it moves to numpy and meanwhile I will lose the gradient. so that I should &lt;code class=&quot;highlighter-rouge&quot;&gt;detach()&lt;/code&gt; so that make Tensor does not requiring grad. And after that can move to numpy.&lt;/p&gt;</content><author><name>dionne</name></author><summary type="html">Stochastic Gradient Descent from scratch</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/sgd.png" /></entry><entry><title type="html">Gradient backward, Chain Rule, Refactoring</title><link href="http://localhost:4000/2020/03/note08-fastai-4/" rel="alternate" type="text/html" title="Gradient backward, Chain Rule, Refactoring" /><published>2020-03-02T00:00:00+09:00</published><updated>2020-03-02T00:00:00+09:00</updated><id>http://localhost:4000/2020/03/note08-fastai-4</id><content type="html" xml:base="http://localhost:4000/2020/03/note08-fastai-4/">&lt;ul&gt;
  &lt;li&gt;This note is divided into 4 section.
    &lt;ul&gt;
      &lt;li&gt;Section1: &lt;a href=&quot;https://spellonyou.github.io/2020/02/note08-fastai-1/&quot;&gt;What is the meaning of ‘deep-learning from foundations?’&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Section2: &lt;a href=&quot;https://spellonyou.github.io/2020/03/note08-fastai-2/&quot;&gt;What’s inside Pytorch Operator?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Section3: &lt;a href=&quot;https://spellonyou.github.io/2020/03/note08-fastai-3/&quot;&gt;Implement forward&amp;amp;backward pass from scratch&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Section4: &lt;a href=&quot;https://spellonyou.github.io/2020/03/note08-fastai-4/&quot;&gt;Gradient backward, Chain Rule, Refactoring&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;” Lecture 08 - Deep Learning From Foundations-part2 “&lt;/p&gt;

&lt;h3 class=&quot;no_toc&quot; id=&quot;homework&quot;&gt;Homework&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://explained.ai/matrix-calculus/index.html&quot;&gt;calculus for machine learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://rockt.github.io/2018/04/30/einsum&quot;&gt;einsum convention&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 class=&quot;no_toc&quot; id=&quot;contents&quot;&gt;CONTENTS&lt;/h3&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#foundation-version&quot; id=&quot;markdown-toc-foundation-version&quot;&gt;Foundation version&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#gradients-backward-pass&quot; id=&quot;markdown-toc-gradients-backward-pass&quot;&gt;Gradients backward pass&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#decompose-function&quot; id=&quot;markdown-toc-decompose-function&quot;&gt;decompose function&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#chain-rule-with-code&quot; id=&quot;markdown-toc-chain-rule-with-code&quot;&gt;chain rule with code&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#check-the-result-using-pytorch-autograd&quot; id=&quot;markdown-toc-check-the-result-using-pytorch-autograd&quot;&gt;check the result using Pytorch autograd&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#refactor-model&quot; id=&quot;markdown-toc-refactor-model&quot;&gt;Refactor model&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#layers-as-classes&quot; id=&quot;markdown-toc-layers-as-classes&quot;&gt;Layers as classes&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#modueforward&quot; id=&quot;markdown-toc-modueforward&quot;&gt;Modue.forward()&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#without-einsum&quot; id=&quot;markdown-toc-without-einsum&quot;&gt;Without einsum&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nnlinear-and-nnmodule&quot; id=&quot;markdown-toc-nnlinear-and-nnmodule&quot;&gt;nn.Linear and nn.Module&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ul&gt;
  &lt;li&gt;Forward process&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-forward.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;foundation-version&quot;&gt;Foundation version&lt;/h3&gt;

&lt;h4 id=&quot;gradients-backward-pass&quot;&gt;Gradients backward pass&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Gradients is output with respect to parameter&lt;/li&gt;
  &lt;li&gt;we’ve done this work in this path(below)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-calculus.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to simplify this calculus, we can just change it into&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y=f(u)&lt;/script&gt;,
&lt;script type=&quot;math/tex&quot;&gt;u=g(x)&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So, you should know of the derivative of each bit on its own, and then you multiply them all together. As a result, it would be &lt;script type=&quot;math/tex&quot;&gt;dy&lt;/script&gt; over &lt;script type=&quot;math/tex&quot;&gt;dx&lt;/script&gt; cross over the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-derivative.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So you can get gradient, output with respect to parameter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-chain_rule.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What order should we calculate?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-calculus.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;color:gray; font-size: 110%; text-align: center;&quot;&gt;BTW, why Jeremy wrote &lt;script type=&quot;math/tex&quot;&gt;\hat y&lt;/script&gt;, not &lt;em&gt;Loss function&lt;/em&gt;?&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h5 id=&quot;decompose-function&quot;&gt;decompose function&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;We want to get derivative of &lt;script type=&quot;math/tex&quot;&gt; w_1 &lt;/script&gt; which forms &lt;script type=&quot;math/tex&quot;&gt;t=x_1 @ w_1 + b_1&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;But, we have a estimation of answer (&lt;em&gt;we call it y hat&lt;/em&gt;) now&lt;/li&gt;
  &lt;li&gt;So, I will decompose funciton to trace target variable.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\overset{\rightharpoonup}{u}\ \ linear_1\ \ \overset{\rightharpoonup}{w}\ \ ReLU\ \ \overset{\rightharpoonup}{v}\ \ linear_2\ \ \overset{\rightharpoonup}{a}\ \ MSE = \hat y&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Using the above forward pass, we can suppose some function from the end.&lt;/li&gt;
  &lt;li&gt;start from &lt;script type=&quot;math/tex&quot;&gt;  \hat y &lt;/script&gt;, We know MSE funciton got two parameters, output, &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; and target &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;from MSE’s input we know &lt;script type=&quot;math/tex&quot;&gt;  linear_2&lt;/script&gt; function’s output and supposing v is input of that function, &lt;script type=&quot;math/tex&quot;&gt;linear_2(v) = u&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;similarly, &lt;em&gt;v&lt;/em&gt; became output of &lt;script type=&quot;math/tex&quot;&gt;ReLU, ReLU(t) = v&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-backward3.jpeg&quot; alt=&quot;&quot; height=&quot;70%&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;chain-rule-with-code&quot;&gt;chain rule with code&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;examplify backward process by random sampling&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To get a variable, I modified forward model a little&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_ping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'x_train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# one linear layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# one relu layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;l3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# one more linear layer
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Be careful we don’t use mse_loss in backward process&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1) start with the very last function, which is loss funciton. MSE&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-mse.jpeg&quot; alt=&quot;&quot; height=&quot;40%&quot; width=&quot;40%&quot; class=&quot;center-image;&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\color{red}{\frac{\partial}{\partial u}MSE(u,y)} \times\frac{\partial}{\partial v}l_2(v)\times\frac{\partial}{\partial t}ReLU(t)\times\frac{\partial}{\partial x}l_1(x)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;If we codify this formula,&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mse_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#mse_input(1000,1), mse_targ (1000,1)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# grad of loss with respect to output of previous layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;And, this can be examplified like below.&lt;/li&gt;
  &lt;li&gt;Notice that input of gradient function is same with forward function&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_ping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'l3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#get value from forward model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;We can just calculate using broadcasting, not using squeeze. then why should do and unsqueeze again?&lt;br /&gt;
🎯 It’s related with random access memory(RAM).. If I don’t &lt;em&gt;squeeze&lt;/em&gt;, (I’m using colab) &lt;strong&gt;it out of RAM&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2) Derivative of linear2 function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial u}MSE(u,y) \times\color{red}{\frac{\partial}{\partial v}l_2(v)} \times \frac {\partial}{\partial t}ReLU(t)\times\frac{\partial}{\partial x}l_1(x)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;This process’s weight dimensions defined by axis=1, axis=2.&lt;/li&gt;
  &lt;li&gt;axis=0 dimension means size of data. This will be summazed by .sum(0) method.&lt;/li&gt;
  &lt;li&gt;unsqeeze(-1)&amp;amp;unsqeeze(1) seperates the dimension, and make a dot product, and vanish axis=0 dimension.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-wayofbackward.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lin_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# grad of matmul with respect to input
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Examplified below&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lin2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_ping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'l2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#get value from forward model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lin2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Notice going reverse order, we’re passing in gradient backward&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3) derivative of ReLU&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-relu.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/4-relugrad.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial u}MSE(u,y) \times \frac{\partial}{\partial v}l_2(v) \times \color{red}{\frac{\partial}{\partial t}ReLU(t)}\times\frac{\partial}{\partial x}l_1(x)&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# grad of relu with respect to input activations
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Examplified below&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_ping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'l1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#get value from forward model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lin2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;4) Derivative of linear1&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Same process with 2) but, this process’s weight has&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial u}MSE(u,y) \times \frac{\partial}{\partial v}l_2(v) \times \frac{\partial}{\partial t}ReLU(t)\times\color{red}{\frac{\partial}{\partial x}l_1(x)}&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lin_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# grad of matmul with respect to input
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Examplified below&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;5) Then it goes backward pass&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_and_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# forward pass:
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# we don't actually need the loss in backward!
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# backward pass:
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mse_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lin_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;relu_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lin_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p style=&quot;color:red; font-size:110;&quot;&gt;Version 1 (Basic)- Wall time: 1.95 s&lt;/p&gt;

&lt;p style=&quot;color:gray; font-size: 130%; text-align: left;&quot;&gt;Summary&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Notice that output of function at forward pass became input of backward pass&lt;/li&gt;
  &lt;li&gt;backpropagation is just the chain rule&lt;/li&gt;
  &lt;li&gt;value loss &lt;em&gt;(loss=mse(out,targ))&lt;/em&gt; is not used in gradient calcuation.
    &lt;ul&gt;
      &lt;li&gt;Because, it doesn’t appear with the weight.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;w1g, w2g, b1g, b2g, ig will be used for optimizer&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;check-the-result-using-pytorch-autograd&quot;&gt;check the result using Pytorch autograd&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;require_grad_&lt;/em&gt; is the magical function, which can automatic differentiation.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;
    &lt;ul&gt;
      &lt;li&gt;This magical auto gradified tensor &lt;strong&gt;keep track&lt;/strong&gt; what happend in forward (taking loss function),&lt;/li&gt;
      &lt;li&gt;and do the backward&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
      &lt;li&gt;So it saves our time to differentiate ourselves&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Postfix underscore means in pytorch, &lt;code class=&quot;highlighter-rouge&quot;&gt;in-place&lt;/code&gt; function, &lt;a href=&quot;https://discuss.pytorch.org/t/what-is-in-place-operation/16244&quot;&gt;What is in-place function?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;⤵️ THis is benchmark…..&lt;/p&gt;

&lt;p style=&quot;color:red; font-size:110;&quot;&gt;Version 2 (torch autograd)- Wall time: 3.81 µs&lt;/p&gt;

&lt;h3 id=&quot;refactor-model&quot;&gt;Refactor model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Amazingly, just refactoring our main pieces, it comes down up to Pytorch package.&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;color:red; font-size: 140%; text-align: center;&quot;&gt;🌟 Implement yourself, Practice, practice, practice! 🌟&lt;/p&gt;

&lt;h4 id=&quot;layers-as-classes&quot;&gt;Layers as classes&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Relu and Linear are layers in oue neural net. -&amp;gt; make it as classes&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the forward, using __call__ for the both of forward &amp;amp; backward. Because ‘&lt;strong&gt;call&lt;/strong&gt;’ means we treat this as a function.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Lin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__call__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Creating a giant outer product, just to sum it, is inefficient!
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Remember that in &lt;em&gt;lin_grad&lt;/em&gt; function, we save bias&amp;amp;weight!!!!!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;💬 inp.g : gradient of the output with respect to the input.
{: style=”color:grey; font-size: 90%; text-align: center;”} &lt;br /&gt;
💬 w.g : gradient of the output with respect to the weight.
{: style=”color:grey; font-size: 90%; text-align: center;”} &lt;br /&gt;
💬 b.g : gradient of the output with respect to the bias.
{: style=”color:grey; font-size: 90%; text-align: center;”} &lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Lin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__call__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;refer to Jeremy’s &lt;strong&gt;Model&lt;/strong&gt; class, he put layers in list&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Dionne’s self-study note: Decomposing Jeremy’s Model class
    &lt;ol&gt;
      &lt;li&gt;init needs weight, bias but not &lt;strong&gt;x data&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;when call that class(a.k.a function) it gave x data and y label!&lt;/li&gt;
      &lt;li&gt;jeremy composited function in layers. x = l(x) &lt;em&gt;so concise…..&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;also utilized that layer list when backward ust reversing it (using python list’s method)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;And he is recursively calling the function on the result of the previous thing. ⬇️&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Q2: Don’t I need to declare magical autograd function, &lt;em&gt;requires_grad_&lt;/em&gt;?{: style=”color:red; font-size: 130%; text-align: center;”}&lt;/p&gt;

&lt;p&gt;[The questions migrated to this article]&lt;/p&gt;

&lt;p style=&quot;color:red; font-size:110;&quot;&gt;Version 3 (refactoring - layer to class)- Wall time: 5.25 µs&lt;/p&gt;

&lt;h4 id=&quot;modueforward&quot;&gt;Modue.forward()&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Duplicate code&lt;/strong&gt; makes execution time slow.
    &lt;ul&gt;
      &lt;li&gt;Role of &lt;code class=&quot;highlighter-rouge&quot;&gt;__call__&lt;/code&gt; changed. No more &lt;code class=&quot;highlighter-rouge&quot;&gt;__call__&lt;/code&gt; for &lt;strong&gt;implementing&lt;/strong&gt; forward pass.&lt;/li&gt;
      &lt;li&gt;By initializing the forward with &lt;code class=&quot;highlighter-rouge&quot;&gt;__call__&lt;/code&gt;, Module.forward() use overriding to maximize reusability. So any layer inherit Module, can use parent’s function.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;gradient of the output with respect to the weight
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;can be reexpressed using einsum,&lt;/p&gt;
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;einsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bi,bj-&amp;gt;ij&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Defining forward and Module enables Pytorch to out almost duplicates&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;color:red; font-size:110;&quot;&gt;Version 4 (Module &amp;amp; einsum)- Wall time: 4.29 µs&lt;/p&gt;

&lt;p&gt;Q2: Isn’t there any way to use broadcasting? Why we should use outer product?{: style=”color:red; font-size: 130%; text-align: center;”}&lt;/p&gt;

&lt;h4 id=&quot;without-einsum&quot;&gt;Without einsum&lt;/h4&gt;

&lt;p&gt;Replacing einsum to matrix product is even more faster.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;einsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bi,bj-&amp;gt;ij&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;can be reexpressed using matrix product,&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p style=&quot;color:red; font-size:110;&quot;&gt;Version 5 (without einsum)- Wall time: 3.81 µs&lt;/p&gt;

&lt;h4 id=&quot;nnlinear-and-nnmodule&quot;&gt;nn.Linear and nn.Module&lt;/h4&gt;

&lt;p&gt;Torch’s package nn.Linear and nn.Module&lt;/p&gt;

&lt;p style=&quot;color:red; font-size:110;&quot;&gt;Version 6 (torch package)- Wall time: 5.01 µs&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Final, Using torch.nn.Linear &amp;amp; torch.nn.Module
~~~python&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;class Model(nn.Module):
    def &lt;strong&gt;init&lt;/strong&gt;(self, n_in, nh, n_out):
        super().&lt;strong&gt;init&lt;/strong&gt;()
        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]
        self.loss = mse&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def __call__(self, x, targ):
    for l in self.layers: x = l(x)
    return self.loss(x.squeeze(), targ)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;class Model():
    def &lt;strong&gt;init&lt;/strong&gt;(self):
        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]
        self.loss = Mse()&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def __call__(self, x, targ):
    for l in self.layers: x = l(x)
    return self.loss(x, targ)

def backward(self):
    self.loss.backward()
    for l in reversed(self.layers): l.backward()        
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;~~~&lt;/p&gt;

&lt;h3 class=&quot;no_toc&quot; id=&quot;footnote&quot;&gt;Footnote&lt;/h3&gt;
&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://forums.fast.ai/t/lesson-8-2019-discussion-wiki/41323/433&quot;&gt;fast.ai forums Lesson-8&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/autograd.html&quot;&gt;pytorch docs - autograd&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/34439/finding-what-methods-a-python-object-has/34452#34452&quot;&gt;stackoverflow - finding methods a object has&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>dionne</name></author><category term="sticky" /><summary type="html">This note is divided into 4 section. Section1: What is the meaning of ‘deep-learning from foundations?’ Section2: What’s inside Pytorch Operator? Section3: Implement forward&amp;amp;backward pass from scratch Section4: Gradient backward, Chain Rule, Refactoring</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/4-classlin.png" /></entry></feed>